{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09706c9c-4406-44ed-9d4b-c21c6bf7e8fb",
   "metadata": {},
   "source": [
    "# OCC One-class classification\n",
    "Laden von Datensatz WELFake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3649dc8d-2873-4714-beab-27c5ddb05256",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# One-class models\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "path = os.path.join(\"../src/data\", \"Saurabh Shahane - Fake_News_Classification\", \"WELFake_Dataset.csv\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df = df.rename(columns={'Title': 'title', 'Text': 'text', 'Label': 'label'})\n",
    "df = df[df['text'].notna() & df['title'].notna()]\n",
    "df['label'] = 1 - df['label'].astype(int)  # Flip labels: 0 → 1, 1 → 0\n",
    "df = df[['title', 'text', 'label']]\n",
    "\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "X = df['title'] + '\\n' + df['text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Vectorize text\n",
    "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec   = vectorizer.transform(X_val)\n",
    "\n",
    "def evaluate_model(name, preds, y_true):\n",
    "    print(f\"== {name} ==\")\n",
    "    print(classification_report(y_true, preds, target_names=[\"Fake\", \"Real\"]))\n",
    "\n",
    "contamination = min(1 - df['label'].mean(), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa698c-cde2-4e99-b8e7-2563e24d44db",
   "metadata": {},
   "source": [
    "## Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd41e759-c26a-4ac2-a78d-527b24ce45fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== IsolationForest ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.45      0.43      0.44      7302\n",
      "        Real       0.42      0.44      0.43      7006\n",
      "\n",
      "    accuracy                           0.43     14308\n",
      "   macro avg       0.43      0.43      0.43     14308\n",
      "weighted avg       0.44      0.43      0.43     14308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_if = IsolationForest(n_estimators=100, contamination=contamination, random_state=42)\n",
    "model_if.fit(X_train_vec)\n",
    "\n",
    "preds_if = model_if.predict(X_val_vec)\n",
    "preds_if = (preds_if == 1).astype(int)\n",
    "\n",
    "evaluate_model('IsolationForest', preds_if, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e28e4b4-1bb7-4018-8d5b-c8dfc3129b8f",
   "metadata": {},
   "source": [
    "## Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79fa121e-b886-485c-be28-ca9ca788d986",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== LocalOutlierFactor ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.53      0.51      0.52      7302\n",
      "        Real       0.51      0.52      0.51      7006\n",
      "\n",
      "    accuracy                           0.52     14308\n",
      "   macro avg       0.52      0.52      0.52     14308\n",
      "weighted avg       0.52      0.52      0.52     14308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lof = LocalOutlierFactor(n_neighbors=20, contamination=contamination, novelty=True)\n",
    "model_lof.fit(X_train_vec)\n",
    "preds_lof = model_lof.predict(X_val_vec)\n",
    "preds_lof = (preds_lof == 1).astype(int)\n",
    "evaluate_model('LocalOutlierFactor', preds_lof, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b96aa-61a1-45f1-8eb0-393d50529330",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a5b215d-40d0-4689-87a9-97665a13a473",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== KNN Distance ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.59      0.23      0.33      7302\n",
      "        Real       0.51      0.83      0.63      7006\n",
      "\n",
      "    accuracy                           0.52     14308\n",
      "   macro avg       0.55      0.53      0.48     14308\n",
      "weighted avg       0.55      0.52      0.48     14308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# 1) Fit KNN with sparse inputs and cosine metric\n",
    "knn = NearestNeighbors(n_neighbors=5)\n",
    "knn.fit(X_train_vec)\n",
    "\n",
    "# 2) Compute distances (sparse→sparse)\n",
    "distances, _ = knn.kneighbors(X_val_vec)\n",
    "\n",
    "# 3) Average distance as anomaly score\n",
    "avg_dist = distances.mean(axis=1)\n",
    "\n",
    "# 4) Threshold top 20% as outliers\n",
    "thresh_knn = np.percentile(avg_dist, 80)\n",
    "preds_knn  = (avg_dist < thresh_knn).astype(int)\n",
    "\n",
    "# 5) Evaluate\n",
    "evaluate_model('KNN Distance', preds_knn, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a12482-b595-40cc-8966-54bce54386a9",
   "metadata": {},
   "source": [
    "# Local Outlier Factor (LOF) Hyperparametertuning\n",
    "## Local Outlier Factor\n",
    "\n",
    "### TODO Erklärung LOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d6295-3c78-47b9-a35b-f85fec4eea11",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45f452e2-7385-4d88-88b0-4339346bddeb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Train/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# One-class classifier and evaluation metrics\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Pipeline utilities\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import os\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.experimental import enable_halving_search_cv  # Needed to enable\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "path = os.path.join(\"../src/data\", \"Saurabh Shahane - Fake_News_Classification\", \"WELFake_Dataset.csv\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df = df.sample(frac=0.1, random_state=42)\n",
    "df = df.rename(columns={'Title': 'title', 'Text': 'text', 'Label': 'label'})\n",
    "df = df[df['text'].notna() & df['title'].notna()]\n",
    "df['label'] = 1 - df['label'].astype(int)  # Flip labels: 0 → 1, 1 → 0\n",
    "df = df[['title', 'text', 'label']]\n",
    "\n",
    "X = df['title'] + '\\n' + df['text']\n",
    "y = df['label']\n",
    "\n",
    "# 2) Split into train / temp (30%) then val/test (each 15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Build the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    # novelty=True lets LOF be used for prediction on unseen data\n",
    "    ('lof', LocalOutlierFactor(novelty=True))\n",
    "])\n",
    "\n",
    "# 4) Evaluation function\n",
    "def evaluate_lof_params(params):\n",
    "    # build vectorizer + LOF (novelty mode)\n",
    "    vec = TfidfVectorizer(\n",
    "        max_features=params['tfidf__max_features'],\n",
    "        ngram_range=params['tfidf__ngram_range'],\n",
    "        stop_words='english'\n",
    "    )\n",
    "    lof = LocalOutlierFactor(\n",
    "        n_neighbors=params['lof__n_neighbors'],\n",
    "        contamination=params['lof__contamination'],\n",
    "        novelty=True\n",
    "    )\n",
    "    \n",
    "    # fit on real‐only training\n",
    "    Xtr = vec.fit_transform(X_train)            # X_train = real+fake ∪ but LOF novelty uses only X_train\n",
    "    lof.fit(Xtr.toarray())                      # LOF requires dense when novelty=True\n",
    "    \n",
    "    # transform validation\n",
    "    Xv = vec.transform(X_val)\n",
    "    raw = lof.predict(Xv.toarray())             # +1=inlier→Real, -1=outlier→Fake\n",
    "    y_pred = np.where(raw==1, 1, 0)\n",
    "    \n",
    "    return accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d524444-6b83-4014-a84e-0634db89518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tfidf__max_features': [20_000, 30_000],\n",
    "    'lof__n_neighbors'   : [20, 40],\n",
    "    'lof__contamination' : [0.4, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5cba20-5951-46c1-87c3-c36cd68fffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/8] {'tfidf__max_features': 20000, 'tfidf__ngram_range': (1, 1), 'lof__n_neighbors': 20, 'lof__contamination': 0.4} → Val acc: 0.5205\n",
      "[2/8] {'tfidf__max_features': 20000, 'tfidf__ngram_range': (1, 1), 'lof__n_neighbors': 20, 'lof__contamination': 0.5} → Val acc: 0.5419\n",
      "[3/8] {'tfidf__max_features': 20000, 'tfidf__ngram_range': (1, 1), 'lof__n_neighbors': 40, 'lof__contamination': 0.4} → Val acc: 0.5493\n",
      "[4/8] {'tfidf__max_features': 20000, 'tfidf__ngram_range': (1, 1), 'lof__n_neighbors': 40, 'lof__contamination': 0.5} → Val acc: 0.5549\n",
      "[5/8] {'tfidf__max_features': 30000, 'tfidf__ngram_range': (1, 1), 'lof__n_neighbors': 20, 'lof__contamination': 0.4} → Val acc: 0.5242\n"
     ]
    }
   ],
   "source": [
    "best_score  = -1\n",
    "best_params = None\n",
    "total = np.prod([len(v) for v in param_grid.values()])\n",
    "i = 0\n",
    "\n",
    "for mf in param_grid['tfidf__max_features']:\n",
    "        for nn in param_grid['lof__n_neighbors']:\n",
    "            for cont in param_grid['lof__contamination']:\n",
    "                i += 1\n",
    "                p = {\n",
    "                    'tfidf__max_features': mf,\n",
    "                    'tfidf__ngram_range': (1,1),\n",
    "                    'lof__n_neighbors': nn,\n",
    "                    'lof__contamination': cont\n",
    "                }\n",
    "                score = evaluate_lof_params(p)\n",
    "                print(f\"[{i}/{total}] {p} → Val acc: {score:.4f}\")\n",
    "                if score > best_score:\n",
    "                    best_score, best_params = score, p.copy()\n",
    "\n",
    "print(\"\\nBest validation accuracy:\", best_score)\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5424a-4062-43cb-92e3-1e2f31e179dd",
   "metadata": {},
   "source": [
    "# TODO: es gibt noch halving search, random search und das alles nach Cross validation nennen/erklären"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118d777-9954-482e-a23b-3ef8f3c0a085",
   "metadata": {},
   "source": [
    "# Übergabe zu Vladi\n",
    "# TOOD platzhalter damit weiß ist einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82783ac4-5f04-43a2-aa23-9913f9c102c3",
   "metadata": {},
   "source": [
    "# Auswahl der Datensätze zur Validierung TODO anpassne der diagramme damit sie gut zu lesen sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851244ff-d0a5-476c-ae2c-54acaab5008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def load_datasets(basepath):\n",
    "    datasets = {}\n",
    "\n",
    "    # 1. Aadya Singh_Fakenews: evaluation.csv, test (1).csv, train (2).csv\n",
    "    folder = os.path.join(basepath, \"Aadya Singh  _fake-and_real_news\")\n",
    "    files = [\"evaluation.csv\", \"test (1).csv\", \"train (2).csv\"]\n",
    "    dfs = [pd.read_csv(os.path.join(folder, f), sep=';') for f in files]\n",
    "    datasets['A'] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 3. clmentbisaillon_Fakenews\n",
    "    folder = os.path.join(basepath, \"clmentbisaillon_Fakenews\")\n",
    "    true = pd.read_csv(os.path.join(folder, \"True.csv\"))\n",
    "    fake = pd.read_csv(os.path.join(folder, \"Fake.csv\"))\n",
    "    df3 = pd.concat([true, fake], ignore_index=True)\n",
    "    if 'text' in df3.columns:\n",
    "        df3 = df3[df3['text'] != \"[empty]\"]\n",
    "    datasets['B'] = df3\n",
    "\n",
    "    # 6. Hassan Amin - fake_or_real_news.csv\n",
    "    datasets['C'] = pd.read_csv(\n",
    "        os.path.join(basepath, \"Hassan Amin-fake_or_real_news.csv/fake_or_real_news.csv\")\n",
    "    )\n",
    "\n",
    "    # 7. Meg Risdal_fake_only\n",
    "    folder = os.path.join(basepath, \"Meg Risdal_fake_only\")\n",
    "    df7 = pd.read_csv(os.path.join(folder, \"fake.csv\"))\n",
    "    # Drop null titles and non-English\n",
    "    if 'titel' in df7.columns:\n",
    "        df7 = df7.dropna(subset=['titel'])\n",
    "        df7 = df7.rename(columns={'titel': 'title'})\n",
    "    if 'language' in df7.columns:\n",
    "        df7 = df7[df7['language'].str.lower() == 'english']\n",
    "    datasets['D'] = df7\n",
    "    \n",
    "    # 8. Ruchi Bhatia_news_articles.csv\n",
    "    df8 = pd.read_csv(os.path.join(basepath, \"Ruchi Bhatia_news_articles.csv/news_articles.csv\"))\n",
    "    # Clean entries\n",
    "    df8 = df8[~df8['title'].str.lower().isin(['no title', 'newsticker'])]\n",
    "    df8 = df8[df8['text'].notna()]\n",
    "    if 'language' in df8.columns:\n",
    "        df8 = df8[df8['language'].str.lower() == 'english']\n",
    "    datasets['E'] = df8\n",
    "    \n",
    "    # 9. Saurabh Shahane - Fake_News_Classification\n",
    "    datasets['F'] = pd.read_csv(\n",
    "        os.path.join(basepath, \"Saurabh Shahane - Fake_News_Classification\", \"WELFake_Dataset.csv\")\n",
    "    )\n",
    "\n",
    "    # 10. andyP/fake_news_en_opensources\n",
    "    datasets['G'] = pd.read_csv(\n",
    "        os.path.join(basepath, \"bigFakeNews\", \"dataFiltered.csv\")\n",
    "    )\n",
    "\n",
    "    return datasets\n",
    "\n",
    "base_path = '../../data'\n",
    "datasets = load_datasets(base_path)\n",
    "# Extract title sets from each DataFrame\n",
    "title_sets = {}\n",
    "for name, df in datasets.items():\n",
    "    if 'title' in df.columns:\n",
    "        title_sets[name] = set(df['title'].dropna().astype(str).str.strip().str.lower())\n",
    "    else:\n",
    "        title_sets[name] = set()\n",
    "# Initialize result matrix\n",
    "dataset_names = list(title_sets.keys())\n",
    "result = pd.DataFrame(index=dataset_names,\n",
    "                      columns=dataset_names,\n",
    "                      dtype=float)\n",
    "# Compute pairwise overlap percentages\n",
    "for i, a in enumerate(dataset_names):\n",
    "    for b in dataset_names[i+1:]:\n",
    "        set_a = title_sets[a]\n",
    "        set_b = title_sets[b]\n",
    "        score_ab = (len(set_a & set_b) / len(set_a) * 100) if set_a else 0.0\n",
    "        score_ba = (len(set_b & set_a) / len(set_b) * 100) if set_b else 0.0\n",
    "        result.loc[a, b] = score_ab\n",
    "        result.loc[b, a] = score_ba\n",
    "\n",
    "# Fill diagonal with 100%\n",
    "for n in dataset_names:\n",
    "    result.loc[n, n] = 100.0\n",
    "\n",
    "result = result.round(2)\n",
    "\n",
    "# Create annotations with percent and unmatched counts\n",
    "annot = pd.DataFrame(index=dataset_names, columns=dataset_names)\n",
    "for a in dataset_names:\n",
    "    for b in dataset_names:\n",
    "        if a == b:\n",
    "            annot.loc[a, b] = \"100%\\n0\"\n",
    "        else:\n",
    "            set_a = title_sets[a]\n",
    "            set_b = title_sets[b]\n",
    "            inter = set_a & set_b\n",
    "            unmatched = len(set_a - set_b)\n",
    "            annot.loc[a, b] = f\"{result.loc[a,b]:.2f}%\\n{unmatched}\"\n",
    "\n",
    "# Plot heatmap\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(result.astype(float), annot=annot.values, fmt=\"\",\n",
    "            cmap='Blues', cbar_kws={'label': 'Übereinstimmung in %'})\n",
    "plt.title('Vergleich der Titel-Übereinstimmung zwischen Datasets\\n'\n",
    "          '(Zahl unter Prozent: Anzahl nicht-übereinstimmender Titel)')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472161e0-25cd-4644-88d5-3d1df01f0df4",
   "metadata": {},
   "source": [
    "## Enternung von Datensatz A, B, C wegen überschneidungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7ca3b-9474-4c92-9d80-ffe7a36abbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_keys = ['A', 'B', 'C']\n",
    "result = result.drop(index=remove_keys, columns=remove_keys)\n",
    "annot  = annot .drop(index=remove_keys, columns=remove_keys)\n",
    "\n",
    "# now plot as before...\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(result.astype(float), annot=annot.values, fmt=\"\",\n",
    "            cmap='Blues', cbar_kws={'label': 'Übereinstimmung in %'})\n",
    "plt.title('Vergleich der Titel-Übereinstimmung zwischen Datasets\\n'\n",
    "          '(Zahl unter Prozent: Anzahl nicht-übereinstimmender Titel)')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2c4e2-56ec-47a0-b572-32425dcd7ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
