{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3b8e57-a702-41ae-a4ce-bbcd77b5b079",
   "metadata": {},
   "source": [
    "#### Kapitel 4\n",
    "## **NLP-Ansatz**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2fe629",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "- Verarbeitung natürlicher Sprache\n",
    "- nutzt verschiedene Verfahren der Textverarbeitung\n",
    "    - Tokenisierung\n",
    "    - Lemmatisierung\n",
    "    - Stoppwortentfernung\n",
    "- Kombination dieser Verfahren auch als *Vorverarbeitung (preprocessing)* bezeichnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b046e",
   "metadata": {},
   "source": [
    "### Vorverarbeitung mit **SpaCy**\n",
    "- entwickelt von Explosion AI\n",
    "- quelloffene Python-Bibliothek für NLP\n",
    "- zahlreiche Sprachmodelle variabler Größe in verschiedenen Sprachen\n",
    "- unterstützt alle wichtigen Textverarbeitungsverfahren\n",
    "- Zusammenfassung einzelner Schritte als Pipeline\n",
    "- bringt eine Reihe vorgefertigter Pipelines mit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f8258",
   "metadata": {},
   "source": [
    "### Training mit **DistilBERT**\n",
    "- **BERT** (*Bidirectional Encoder Representations from Transformers*)\n",
    "    - ist ein quelloffenes NLP-Sprachmodell von Google\n",
    "    - basiert auf der Transformer-Architektur\n",
    "    - Besonderheit: arbeitet bidirektional\n",
    "    - analysiert Text in beide Richtungen\n",
    "- **DistilBERT**\n",
    "    - \"destillierte\" Version von BERT\n",
    "    - 40 % kleiner\n",
    "    - 60 % schneller\n",
    "    - 97 % der Qualität"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889412fc",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Natural Language Processing angewandt auf Welfake\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54371f5-fe46-4f6e-854f-d38d022be377",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb8fd16-fdc5-4d19-93d8-5a7b40919ca2",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch<2.7,>=2.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (2.5.1+cu121)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from transformers[torch]) (1.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch<2.7,>=2.1->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch<2.7,>=2.1->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from torch<2.7,>=2.1->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from sympy==1.13.1->torch<2.7,>=2.1->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from jinja2->torch<2.7,>=2.1->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01367881",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\teo\\documents\\studium\\_master\\mustererkennung\\.venv\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 4.6 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 4.8 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 5.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.5 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy && python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a8619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa420b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.0\n",
      "SpaCy version: 3.8.7\n",
      "Transformers version: 4.52.4\n",
      "Torch version: 2.5.1+cu121\n",
      "Cuda version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 2060 SUPER\n",
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "# Version Checks\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"SpaCy version:\", spacy.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Cuda version:\", torch.version.cuda)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Initialize Parallelization\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86b3abe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (50493, 4)\n",
      "Eval:  (10820, 4)\n",
      "Test:  (10821, 4)\n",
      "       Unnamed: 0  \\\n",
      "24388       24388   \n",
      "40608       40608   \n",
      "66652       66652   \n",
      "71224       71224   \n",
      "17060       17060   \n",
      "\n",
      "                                                                                                                                  title  \\\n",
      "24388                              THE FACE OF THE DEMOCRAT PARTY Has A Message For The Tea Party And You Won’t Want To Miss It…[VIDEO]   \n",
      "40608  INCOMING FRESHMEN Are Put On Notice With Welcome Letter From U of Chicago Dean Of Students…”Trigger Warning” Crybabies Stay Home   \n",
      "66652                                     REPUBLICANS CALL FOR ANSWERS: Did Wasserman-Schultz and Podesta Just Get Caught In A Big Lie?   \n",
      "71224                         EXTORTION? HOW IRAN Used Nuke Deal To Force Obama To Retreat From Embarrassing “Red Line” Threat To Syria   \n",
      "17060                                                                   Democrats want strong response to intel report on 2016 election   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
      "24388                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         This ass-clown reminds us of why term limits are so important. Leisa and I saw Rep. Rangel (D-NY) up close and personal last week when we visited the Capitol building as guests of Rep. Mike Bishop (R-MI). We were shocked at some of the people who have been elected to represent our nation. 20% of the House members looked like they should be roaming the halls of a nursing home  NOT the halls of Congress!  These people have no business making serious decisions on behalf of our country. Charlie Rangel is a perfect example of our assertion It s no secret that Democrats can t stand the Tea Party, but rarely do they express their hatred out loud like Rep. Charlie Rangel did. In a moment caught on camera, the Democrat Congressman let reporters know what he really thinks about the coalition of citizens who believe in individual liberty and small government (some of whom are undoubtedly his own constituents).TheBlaze reports:Rep. Charlie Rangel (D-N.Y.) had harsh words for Tea Party Republicans during a town hall he hosted Tuesday in New York City. The outspoken Democrat was asked by TheBlaze about what he thinks motivates the more conservative wing of the House Republicans. They come from states that used to own slaves,  Rangel said of his Tea Party colleagues.  They come from states that the Confederate Army was pledged allegiance to. They come from states that the Ku Klux Klan and voters rights and all of those things came into play. [T]hey left the Democratic Party, thank God, they joined the Republican Party and they like being among themselves,  Rangel added.They even got his comments on video here:Via: Deneenborelli   \n",
      "40608                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Wow! The University of Chicago sends impressive letter to incoming Freshman warning them that freedom of speech is alive and well at their college. This letter makes it pretty clear that they will not be joining with hundreds of other colleges across America to squelch the free speech rights of anyone who disagrees with the Black Lives Matter, progressive social justice warrior nonsense.After a student at the University of Illinois Chicago Hyde Park campus threatened to shoot up the campus and  Kill White devils in November 2015, over the shooting of a young black man by police in Chicago, the school made the decision to shut down the campus for a day. Colleges need to get out in front of this social justice warrior/Black Lives Matter terror movement before it gets out of hand on college campuses this year. In a welcome letter to freshmen, the College made clear that it does not condone safe spaces or trigger warnings: pic.twitter.com/9ep3n0ZbgV  The Chicago Maroon (@ChicagoMaroon) August 24, 2016Here is the video showing the shut down of the University of Chicago campus:   \n",
      "66652  Busted! Even moderate Republican Susan Collins of Maine said it best when she questioned how Wasserman-Schultz wouldn t know of the payment to Fusion GPS: It s difficult to imagine that a campaign chairman, that the head of the DNC would not know of an expenditure of this magnitude and significance. She and John Podesta testified last month that they knew nothing of the payment for a dossier on Trump Oops! Now, Republicans want answers:Congressional Republicans on Sunday called for Democrats John Podesta and Rep. Debbie Wasserman Schultz to provide further answers about their party paying for a dossier on President Trump s alleged ties to Russia, after telling Senate investigators last month that they had no knowledge of such payments.Wasserman Schultz is the former chairman of the Democratic National Committee, and Podesta was the chairman of Hillary Clinton s 2016 presidential campaign. Both groups purportedly paid millions for research that led to the dossier, The Washington Post reported last week.Trey Gowdy, chairman of the House Oversight Committee, suggested on  Fox News Sunday  that the DNC paying a law firm for so-called opposition research connected to the dossier was tantamount to money laundering. I m not an election law expert, but the good news is you don t have to be, to understand the absurdity of believing that you can launder all of your campaign money by just hiring a law firm,  said Gowdy, a former federal prosecutor.  So I m interested in that. He also seemed to question Podesta and Wasserman Schultz telling the Senate Intelligence Committee last month that they didn t know who paid for the dossier. I am also interested in sharing some memory tricks with folks at the DNC because no one can remember who paid $10 million to a law firm to do oppo research,  Gowdy said.  I find that stunning. $10 million and no one can remember who authorized it, who approved it, who said,  This is a really good idea. When questioned about the issue by Fox News last week on Capitol Hill, Wasserman Schultz said only:  I wasn t aware of the arrangement at all. HOW COULD SHE NOT KNOW ABOUT THE ARRANGEMENT?READ MORE: FOX NEWS   \n",
      "71224                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   If I were a European and was forced to deal with the massive influx of Muslim refugees from Syria, I d be pointing the finger at President Obama, who clearly can t himself when it comes to caving to Iran.Foreign Affairs journalist for the Wall Street journal, Jay Solomon told MSNBC s Andrea Mitchell that Iran actually threatened to end nuke talks if Obama enforced his  red line  threat with Iran:.@WSJSolomon: Iran threatened to end nuclear talks if @POTUS enforced red line against Assad after chemical attack: pic.twitter.com/czFeFA2K10  Kenan Rahmani   (@KenanRahmani) August 22, 2016   \n",
      "17060                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     WASHINGTON (Reuters) - The top Democrats on the U.S. Senate and House of Representatives intelligence committees said on Friday a report on Russian activity related to the 2016 U.S. election should inspire a strong response to prevent a repeat. “The strength of America’s democracy will be measured, in part, on how we respond, and the steps we take to develop a robust and proactive cyber strategy,” said Mark Warner, the top Democrat on the Senate panel. Representative Adam Schiff, his counterpart on the House panel, said Congress must undertake “thorough investigations” to determine what happened and how, and how to protect the U.S. government.    \n",
      "\n",
      "       label  \n",
      "24388      1  \n",
      "40608      1  \n",
      "66652      1  \n",
      "71224      1  \n",
      "17060      0  \n"
     ]
    }
   ],
   "source": [
    "# Data Path\n",
    "csv_path = \"../src/data/Saurabh Shahane - Fake_News_Classification/WELFake_Dataset.csv\"\n",
    "\n",
    "# Read with semicolon separator\n",
    "df = pd.read_csv(csv_path, sep=',')\n",
    "\n",
    "# Split Data\n",
    "df_train, df_temp = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42, stratify=df_temp['label'])\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Train:\", df_train.shape)\n",
    "print(\"Eval: \", df_val.shape)\n",
    "print(\"Test: \", df_test.shape)\n",
    "\n",
    "# first 5 rows of dataset\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514b554",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline\n",
    "- Lower Case\n",
    "    - Kleinschreibung\n",
    "- Tokenisierung\n",
    "    - Aufteilung des Textes in kleinste Einheiten (\"tokens\")\n",
    "- Lemmatisierung\n",
    "    - gebeugte Wörter werden auf ihren Stamm (\"lemma\") zurückgeführt\n",
    "    - Bsp.: *going* → *go*\n",
    "- Stop Word Removal\n",
    "    - Entfernung häufiger Wörter mit größtenteils grammatikalischer Funktion und wenig Inhalt (\"stop words\")\n",
    "    - Bsp.: *the*, *and*, *in*, *of*, *with*, *but* etc.\n",
    "- Punctuation Removal\n",
    "    - Entfernung von Satzzeichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8679b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preprocessing\n",
    "def preprocess_text(text, print_tokens=False):\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    if print_tokens:\n",
    "        print(tokens)\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d94f60d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ass', 'clown', 'remind', 'term', 'limit', 'important', 'leisa', 'see', 'rep.', 'rangel', 'd', 'ny', 'close', 'personal', 'week', 'visit', 'capitol', 'building', 'guest', 'rep.', 'mike', 'bishop', 'r', 'mi', 'shock', 'people', 'elect', 'represent', 'nation', '20', 'house', 'member', 'look', 'like', 'roam', 'hall', 'nursing', 'home', ' ', 'hall', 'congress', ' ', 'people', 'business', 'make', 'decision', 'behalf', 'country', 'charlie', 'rangel', 'perfect', 'example', 'assertion', 's', 'secret', 'democrats', 't', 'stand', 'tea', 'party', 'rarely', 'express', 'hatred', 'loud', 'like', 'rep.', 'charlie', 'rangel', 'moment', 'catch', 'camera', 'democrat', 'congressman', 'let', 'reporter', 'know', 'think', 'coalition', 'citizen', 'believe', 'individual', 'liberty', 'small', 'government', 'undoubtedly', 'constituents).theblaze', 'report', 'rep.', 'charlie', 'rangel', 'd', 'n.y.', 'harsh', 'word', 'tea', 'party', 'republicans', 'town', 'hall', 'host', 'tuesday', 'new', 'york', 'city', 'outspoken', 'democrat', 'ask', 'theblaze', 'think', 'motivate', 'conservative', 'wing', 'house', 'republicans', 'come', 'state', 'slave', ' ', 'rangel', 'say', 'tea', 'party', 'colleague', ' ', 'come', 'state', 'confederate', 'army', 'pledge', 'allegiance', 'come', 'state', 'ku', 'klux', 'klan', 'voter', 'right', 'thing', 'come', 'play', 't]hey', 'leave', 'democratic', 'party', 'thank', 'god', 'join', 'republican', 'party', 'like', ' ', 'rangel', 'add', 'get', 'comment', 'video', 'deneenborelli']\n",
      "['wow', 'university', 'chicago', 'send', 'impressive', 'letter', 'income', 'freshman', 'warn', 'freedom', 'speech', 'alive', 'college', 'letter', 'make', 'pretty', 'clear', 'join', 'hundred', 'college', 'america', 'squelch', 'free', 'speech', 'right', 'disagree', 'black', 'life', 'matter', 'progressive', 'social', 'justice', 'warrior', 'nonsense', 'student', 'university', 'illinois', 'chicago', 'hyde', 'park', 'campus', 'threaten', 'shoot', 'campus', ' ', 'kill', 'white', 'devil', 'november', '2015', 'shooting', 'young', 'black', 'man', 'police', 'chicago', 'school', 'decision', 'shut', 'campus', 'day', 'college', 'need', 'social', 'justice', 'warrior', 'black', 'life', 'matter', 'terror', 'movement', 'get', 'hand', 'college', 'campus', 'year', 'welcome', 'letter', 'freshman', 'college', 'clear', 'condone', 'safe', 'space', 'trigger', 'warning', 'pic.twitter.com/9ep3n0zbgv', ' ', 'chicago', 'maroon', '@chicagomaroon', 'august', '24', '2016here', 'video', 'show', 'shut', 'university', 'chicago', 'campus']\n",
      "['bust', 'moderate', 'republican', 'susan', 'collins', 'maine', 'say', 'well', 'question', 'wasserman', 'schultz', 'wouldn', 't', 'know', 'payment', 'fusion', 'gps', 's', 'difficult', 'imagine', 'campaign', 'chairman', 'head', 'dnc', 'know', 'expenditure', 'magnitude', 'significance', 'john', 'podesta', 'testify', 'month', 'know', 'payment', 'dossier', 'trump', 'oops', 'republicans', 'want', 'answer', 'congressional', 'republicans', 'sunday', 'call', 'democrats', 'john', 'podesta', 'rep.', 'debbie', 'wasserman', 'schultz', 'provide', 'answer', 'party', 'pay', 'dossier', 'president', 'trump', 's', 'allege', 'tie', 'russia', 'tell', 'senate', 'investigator', 'month', 'knowledge', 'payment', 'wasserman', 'schultz', 'chairman', 'democratic', 'national', 'committee', 'podesta', 'chairman', 'hillary', 'clinton', 's', '2016', 'presidential', 'campaign', 'group', 'purportedly', 'pay', 'million', 'research', 'lead', 'dossier', 'washington', 'post', 'report', 'week', 'trey', 'gowdy', 'chairman', 'house', 'oversight', 'committee', 'suggest', ' ', 'fox', 'news', 'sunday', ' ', 'dnc', 'pay', 'law', 'firm', 'call', 'opposition', 'research', 'connect', 'dossier', 'tantamount', 'money', 'laundering', 'm', 'election', 'law', 'expert', 'good', 'news', 'don', 't', 'understand', 'absurdity', 'believe', 'launder', 'campaign', 'money', 'hire', 'law', 'firm', ' ', 'say', 'gowdy', 'federal', 'prosecutor', ' ', 'm', 'interested', 'question', 'podesta', 'wasserman', 'schultz', 'tell', 'senate', 'intelligence', 'committee', 'month', 'didn', 't', 'know', 'pay', 'dossier', 'interested', 'share', 'memory', 'trick', 'folk', 'dnc', 'remember', 'pay', '$', '10', 'million', 'law', 'firm', 'oppo', 'research', ' ', 'gowdy', 'say', ' ', 'find', 'stunning', '$', '10', 'million', 'remember', 'authorize', 'approve', 'say', ' ', 'good', 'idea', 'question', 'issue', 'fox', 'news', 'week', 'capitol', 'hill', 'wasserman', 'schultz', 'say', ' ', 'wasn', 't', 'aware', 'arrangement', 'know', 'arrangement?read', 'fox', 'news']\n",
      "['european', 'force', 'deal', 'massive', 'influx', 'muslim', 'refugee', 'syria', 'd', 'point', 'finger', 'president', 'obama', 'clearly', 't', 'come', 'cave', 'iran', 'foreign', 'affairs', 'journalist', 'wall', 'street', 'journal', 'jay', 'solomon', 'tell', 'msnbc', 's', 'andrea', 'mitchell', 'iran', 'actually', 'threaten', 'end', 'nuke', 'talk', 'obama', 'enforce', ' ', 'red', 'line', ' ', 'threat', 'iran:.@wsjsolomon', 'iran', 'threaten', 'end', 'nuclear', 'talk', '@potus', 'enforce', 'red', 'line', 'assad', 'chemical', 'attack', 'pic.twitter.com/czfefa2k10', ' ', 'kenan', 'rahmani', '  ', '@kenanrahmani', 'august', '22', '2016']\n",
      "['washington', 'reuters', 'democrats', 'u.s.', 'senate', 'house', 'representatives', 'intelligence', 'committee', 'say', 'friday', 'report', 'russian', 'activity', 'relate', '2016', 'u.s.', 'election', 'inspire', 'strong', 'response', 'prevent', 'repeat', 'strength', 'america', 'democracy', 'measure', 'respond', 'step', 'develop', '\\xa0', 'robust', 'proactive', 'cyber', 'strategy', 'say', 'mark', 'warner', 'democrat', 'senate', 'panel', 'representative', 'adam', 'schiff', 'counterpart', 'house', 'panel', 'say', 'congress', 'undertake', 'thorough', 'investigation', 'determine', 'happen', 'protect', 'u.s.', 'government']\n"
     ]
    }
   ],
   "source": [
    "# Test Preprocessing (can be skipped)\n",
    "df_train_sample = df_train[:5]['text'].astype(str).apply(preprocess_text, print_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67a9dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4220b8c11b59470786a6925d75796746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=8416), Label(value='0 / 8416'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211a06a19b3d49629f1b9ea240344465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1804), Label(value='0 / 1804'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24388    ass clown remind term limit important leisa se...\n",
      "40608    wow university chicago send impressive letter ...\n",
      "66652    bust moderate republican susan collins maine s...\n",
      "71224    european force deal massive influx muslim refu...\n",
      "17060    washington reuters democrats u.s. senate house...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply Preprocessing\n",
    "df_train['text'] = df_train['text'].astype(str).parallel_apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].astype(str).parallel_apply(preprocess_text)\n",
    "\n",
    "print(df_train['text'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2854e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenizing\n",
    "train_encodings = tokenizer(list(df_train['text']), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(df_test['text']), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6d910",
   "metadata": {},
   "source": [
    "### Die wichtigsten Trainingsparameter\n",
    "- `num_train_epochs=2`\n",
    "    - Anzahl der Trainingsepochen\n",
    "    - ausreichend für großen, diversen Trainingsdatensatz\n",
    "    - zu wenige Epochen = zu allgemeines Modell (*underfitting*)\n",
    "    - zu viele Epochen = zu spezielles Modell (*overfitting*)\n",
    "- `per_device_train_batch_size=32`\n",
    "    - Schrittgröße beim Training\n",
    "    - kleinere Batches erzeugen Rauschen\n",
    "    - Rauschen verhindert Overfitting\n",
    "- `weight_decay=0.01`\n",
    "    - Form der L2-Regularisierung\n",
    "    - verhindert Overfitting durch Bestrafung zu hoher Gewichte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b783daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3156' max='3156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3156/3156 20:12, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.045197</td>\n",
       "      <td>0.984659</td>\n",
       "      <td>0.984661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.043768</td>\n",
       "      <td>0.988079</td>\n",
       "      <td>0.988079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5255\n",
      "           1       0.99      0.99      0.99      5566\n",
      "\n",
      "    accuracy                           0.99     10821\n",
      "   macro avg       0.99      0.99      0.99     10821\n",
      "weighted avg       0.99      0.99      0.99     10821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Translate to Huggingface Dataset Format\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'label': list(df_train['label'])\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask'],\n",
    "    'label': list(df_test['label'])\n",
    "})\n",
    "\n",
    "# Load Model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Training Parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Define Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(logits), dim=1)\n",
    "    report = classification_report(labels, preds, output_dict=True)\n",
    "    return {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    }\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start Training\n",
    "trainer.train()\n",
    "\n",
    "# Evaluation\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = torch.argmax(torch.tensor(predictions.predictions), dim=1)\n",
    "print(classification_report(df_test['label'], pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf9c64",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68378ae",
   "metadata": {},
   "source": [
    "#### Kapitel 8\n",
    "## Ausblick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47f870",
   "metadata": {},
   "source": [
    "### Mehrklassige Datensätze\n",
    "Die meisten Fake News Datensätze sind binär klassifiziert.  \n",
    "Es gibt aber auch Datensätze, die deutlich komplexer aufgebaut sind.\n",
    "___\n",
    "#### Beispiel 1: **[LIAR](https://datasets.activeloop.ai/docs/ml/datasets/liar-dataset/)**\n",
    "*LIAR* enthält 12,8 Tausend Phrasen und kurze Statements aus einem Zeitraum von 10 Jahren, welche in 6 Kategorien unterteilt sind.  \n",
    "Die Kategorien sind dabei nach Glaubwürdigkeit sortiert, erweitern den binären Klassifikator also um eine simple Abstufung.\n",
    "- `true`\n",
    "- `mostly-true`\n",
    "- `half-true`\n",
    "- `barely-true`\n",
    "- `false`\n",
    "- `pants-fire`\n",
    "___\n",
    "#### Beispiel 2: **[Fakeddit](https://github.com/entitize/Fakeddit)**\n",
    "*Fakeddit* ist eine Initiative zur Klassifizierung von Newsartikeln.  \n",
    "Über eine CodaLab Competition wurden im Zeitraum von 2020 bis 2022 über 1 Million Artikel klassifiziert.  \n",
    "Dabei waren folgende 6 Klassen vorgegeben.\n",
    "- `true`\n",
    "- `satire/parody`\n",
    "- `misleading content`\n",
    "- `manipulated content`\n",
    "- `false connection`\n",
    "- `imposter content`\n",
    "___\n",
    "#### Beispiel 3: **[andyP](https://huggingface.co/datasets/andyP/fake_news_en_opensources)**\n",
    "Dieser Datensatz enthält 5,9 Millionen Einträge, welche in 12 Klassen eingeteilt sind.\n",
    "- `reliable`\n",
    "- `ploitical`\n",
    "- `bias`\n",
    "- `fake`\n",
    "- `conspiracy`\n",
    "- `rumor`\n",
    "- `unknown`\n",
    "- `clickbait`\n",
    "- `unreliable`\n",
    "- `satire`\n",
    "- `junksci`\n",
    "- `hate`\n",
    "___\n",
    "Komplexere Einteilungen schaffen ein deutlich relistischeres Bild der Online-Newsartikellandschaft, benötigen jedoch einen ausreichend große und qualitativ hochwertige Datensätze."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
