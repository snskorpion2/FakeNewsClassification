{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4c2146-1a43-41bd-bfda-034d3008bdc7",
   "metadata": {},
   "source": [
    "# Compare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8963ff5d-58bc-4ccd-88e6-6377ff6a2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Dict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import uniform, randint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba5be13-10ad-489e-89cb-139dc3abc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lengths_random(\n",
    "    dfs: Dict[str, pd.DataFrame],\n",
    "    random_state: int = 42\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each DataFrame in dfs, sample down to the minimum length among them.\n",
    "\n",
    "    Args:\n",
    "        dfs: dict mapping names to DataFrames.\n",
    "        random_state: seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict of sampled DataFrames.\n",
    "    \"\"\"\n",
    "    min_len = min(len(df) for df in dfs.values())\n",
    "    print(f\"Sampling all datasets to {min_len} rows each (smallest dataset size)\")\n",
    "    return {\n",
    "        name: df.sample(n=min_len, random_state=random_state)\n",
    "                .reset_index(drop=True)\n",
    "        for name, df in dfs.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48771be-2c7f-4aed-919d-5bc76dc43bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset B: WELFake by Saurabh Shahane\n",
    "def load_B(path: str = \"../../data/Saurabh Shahane - Fake_News_Classification/WELFake_Dataset.csv\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'Title': 'title', 'Text': 'text', 'Label': 'label'})\n",
    "    df['label'] = 1 - df['label'].astype(int)  # Flip labels: 0 → 1, 1 → 0\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "\n",
    "# Dataset C: Fake News by GonzaloA\n",
    "def load_C(\n",
    "    train_path: str = \"../../data/GonzaloA - fake_news/train_without_reuters.csv\",\n",
    "    val_path: str   = \"../../data/GonzaloA - fake_news/evaluation_without_reuters.csv\",\n",
    "    test_path: str  = \"../../data/GonzaloA - fake_news/test_without_reuters.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    parts = []\n",
    "    for p in [train_path, val_path, test_path]:\n",
    "        parts.append(\n",
    "            pd.read_csv(p,sep=';')\n",
    "        )\n",
    "    df = pd.concat(parts, ignore_index=True)\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'label'})\n",
    "    if 'content' in df.columns and 'text' not in df.columns:\n",
    "        df = df.rename(columns={'content': 'text'})\n",
    "        \n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "# Dataset D: fake-news-detection-dataset-English by ErfanMoosaviMonazzah\n",
    "def load_D(\n",
    "    train_path: str = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/train.tsv\",\n",
    "    val_path: str   = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/validation.tsv\",\n",
    "    test_path: str  = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/test.tsv\"\n",
    ") -> pd.DataFrame:\n",
    "    parts = [\n",
    "        pd.read_csv(train_path, sep='\\t', dtype=str),\n",
    "        pd.read_csv(val_path, sep='\\t', dtype=str),\n",
    "        pd.read_csv(test_path, sep='\\t', dtype=str)\n",
    "    ]\n",
    "    df = pd.concat(parts, ignore_index=True)\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "# Dataset E: Fake News Detection by Bhavik Jikadara\n",
    "def load_E(\n",
    "    fake_path: str = \"../../data/Bhavik Jikadara - Fake News Detection/fake.csv\",\n",
    "    real_path: str = \"../../data/Bhavik Jikadara - Fake News Detection/true.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    df_fake = pd.read_csv(fake_path, dtype=str)\n",
    "    df_real = pd.read_csv(real_path, dtype=str)\n",
    "    df_fake['label'] = '0'\n",
    "    df_real['label'] = '1'\n",
    "    df = pd.concat([df_fake, df_real], ignore_index=True)\n",
    "\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4bd4891-ec65-4069-b005-df86867f2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes rows where 'title' or 'text' is missing or empty.\n",
    "    \"\"\"\n",
    "    return df.dropna(subset=['title', 'text']).query(\"title != '' and text != ''\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9631ed8a-a8e9-4baa-b6cb-05f4626f6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_normalized(random_state: int = 42) -> Dict[str, pd.DataFrame]:\n",
    "    raw_dfs = {\n",
    "        'B': load_B(),\n",
    "        'C': load_C(),\n",
    "        'D': load_D(),\n",
    "        'E': load_E()\n",
    "    }\n",
    "\n",
    "    # Clean before normalization\n",
    "    cleaned_dfs = {name: clean_dataframe(df) for name, df in raw_dfs.items()}\n",
    "    return normalize_lengths_random(cleaned_dfs, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a71a88-ffc5-4247-b99d-1a57076283cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling all datasets to 40587 rows each (smallest dataset size)\n",
      "Dataset B: (40587, 3)\n",
      "Dataset C: (40587, 3)\n",
      "Dataset D: (40587, 3)\n",
      "Dataset E: (40587, 3)\n"
     ]
    }
   ],
   "source": [
    "    datasets = load_all_normalized()\n",
    "    for name, df in datasets.items():\n",
    "        print(f\"Dataset {name}:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbdbf38-7177-4420-941f-101e01659dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2912da0-95dd-49a5-9a0c-95a7bfe2bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = ['B', 'C', 'D', 'E']\n",
    "results = []\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef2bc1c-0991-4372-a015-8756139d8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model on datasets: ('B',) | Testing on: ['C', 'D', 'E'] ===\n",
      "Trained and saved model to models\\logreg_B.joblib\n",
      "→ Duration: 0:02:12.114495\n",
      "→ Validation Accuracy: 0.9650\n",
      "\n",
      "=== Training model on datasets: ('C',) | Testing on: ['B', 'D', 'E'] ===\n",
      "Trained and saved model to models\\logreg_C.joblib\n",
      "→ Duration: 0:01:49.291981\n",
      "→ Validation Accuracy: 0.9767\n",
      "\n",
      "=== Training model on datasets: ('D',) | Testing on: ['B', 'C', 'E'] ===\n",
      "Trained and saved model to models\\logreg_D.joblib\n",
      "→ Duration: 0:01:47.072215\n",
      "→ Validation Accuracy: 0.9925\n",
      "\n",
      "=== Training model on datasets: ('E',) | Testing on: ['B', 'C', 'D'] ===\n",
      "Trained and saved model to models\\logreg_E.joblib\n",
      "→ Duration: 0:01:40.996383\n",
      "→ Validation Accuracy: 0.9967\n",
      "\n",
      "=== Training model on datasets: ('B', 'C') | Testing on: ['D', 'E'] ===\n",
      "Trained and saved model to models\\logreg_B_C.joblib\n",
      "→ Duration: 0:04:11.493907\n",
      "→ Validation Accuracy: 0.9680\n",
      "\n",
      "=== Training model on datasets: ('B', 'D') | Testing on: ['C', 'E'] ===\n",
      "Trained and saved model to models\\logreg_B_D.joblib\n",
      "→ Duration: 0:04:04.928777\n",
      "→ Validation Accuracy: 0.9797\n",
      "\n",
      "=== Training model on datasets: ('B', 'E') | Testing on: ['C', 'D'] ===\n",
      "Trained and saved model to models\\logreg_B_E.joblib\n",
      "→ Duration: 0:03:54.481117\n",
      "→ Validation Accuracy: 0.9815\n",
      "\n",
      "=== Training model on datasets: ('C', 'D') | Testing on: ['B', 'E'] ===\n",
      "Trained and saved model to models\\logreg_C_D.joblib\n",
      "→ Duration: 0:03:47.058606\n",
      "→ Validation Accuracy: 0.9902\n",
      "\n",
      "=== Training model on datasets: ('C', 'E') | Testing on: ['B', 'D'] ===\n",
      "Trained and saved model to models\\logreg_C_E.joblib\n",
      "→ Duration: 0:03:45.417652\n",
      "→ Validation Accuracy: 0.9897\n",
      "\n",
      "=== Training model on datasets: ('D', 'E') | Testing on: ['B', 'C'] ===\n",
      "Trained and saved model to models\\logreg_D_E.joblib\n",
      "→ Duration: 0:03:38.657594\n",
      "→ Validation Accuracy: 0.9985\n",
      "\n",
      "=== Training model on datasets: ('B', 'C', 'D') | Testing on: ['E'] ===\n",
      "Trained and saved model to models\\logreg_B_C_D.joblib\n",
      "→ Duration: 0:06:13.603807\n",
      "→ Validation Accuracy: 0.9784\n",
      "\n",
      "=== Training model on datasets: ('B', 'C', 'E') | Testing on: ['D'] ===\n",
      "Trained and saved model to models\\logreg_B_C_E.joblib\n",
      "→ Duration: 0:06:10.695853\n",
      "→ Validation Accuracy: 0.9786\n",
      "\n",
      "=== Training model on datasets: ('B', 'D', 'E') | Testing on: ['C'] ===\n",
      "Trained and saved model to models\\logreg_B_D_E.joblib\n",
      "→ Duration: 0:05:58.381262\n",
      "→ Validation Accuracy: 0.9863\n",
      "\n",
      "=== Training model on datasets: ('C', 'D', 'E') | Testing on: ['B'] ===\n",
      "Trained and saved model to models\\logreg_C_D_E.joblib\n",
      "→ Duration: 0:05:43.587989\n",
      "→ Validation Accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for r in range(1, len(all_sets)):\n",
    "    for combo in itertools.combinations(all_sets, r):        \n",
    "        model_name = '_'.join(combo)\n",
    "        model_path = Path(f\"models/logreg_{model_name}.joblib\")\n",
    "\n",
    "        df_trainval = pd.concat([datasets[d] for d in combo], ignore_index=True)\n",
    "        test_sets = [d for d in all_sets if d not in combo]\n",
    "        df_test = pd.concat([datasets[d] for d in test_sets], ignore_index=True)\n",
    "\n",
    "        X = df_trainval['title'] + '\\n' + df_trainval['text']\n",
    "        y = df_trainval['label']\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        print(f\"\\n=== Training model on datasets: {combo} | Testing on: {test_sets} ===\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=13954,\n",
    "                ngram_range=(1, 2),\n",
    "                stop_words=None,\n",
    "                max_df=0.8891916614020643,\n",
    "                min_df=3\n",
    "            )),\n",
    "            ('clf', LogisticRegression(\n",
    "                C=8.725368061523762,\n",
    "                class_weight='balanced',\n",
    "                penalty='elasticnet',\n",
    "                l1_ratio=0.6760522571867544,\n",
    "                solver='saga',\n",
    "                max_iter=1000\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        if model_path.exists():\n",
    "            pipeline = joblib.load(model_path)\n",
    "            print(f\"Loaded model from {model_path}\")\n",
    "        else:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            joblib.dump(pipeline, model_path)\n",
    "            print(f\"Trained and saved model to {model_path}\")\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        print(f\"→ Duration: {str(end_time - start_time)}\")\n",
    "\n",
    "        val_preds = pipeline.predict(X_val)\n",
    "        test_preds = pipeline.predict(df_test['title'] + '\\n' + df_test['text'])\n",
    "\n",
    "        val_acc = accuracy_score(y_val, val_preds)\n",
    "        test_acc = accuracy_score(df_test['label'], test_preds)\n",
    "        \n",
    "        print(f\"→ Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            'train_on': combo,\n",
    "            'test_on': test_sets,\n",
    "            'val_accuracy': val_acc,\n",
    "            'test_accuracy': test_acc\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0e433b-a8ad-44ef-bbb7-adbd2c8e3f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_on</th>\n",
       "      <th>test_on</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(B,)</td>\n",
       "      <td>[C, D, E]</td>\n",
       "      <td>0.965016</td>\n",
       "      <td>0.977292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(C,)</td>\n",
       "      <td>[B, D, E]</td>\n",
       "      <td>0.976718</td>\n",
       "      <td>0.943956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(D,)</td>\n",
       "      <td>[B, C, E]</td>\n",
       "      <td>0.992486</td>\n",
       "      <td>0.939110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(E,)</td>\n",
       "      <td>[B, C, D]</td>\n",
       "      <td>0.996674</td>\n",
       "      <td>0.933870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(B, C)</td>\n",
       "      <td>[D, E]</td>\n",
       "      <td>0.967970</td>\n",
       "      <td>0.996354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(B, D)</td>\n",
       "      <td>[C, E]</td>\n",
       "      <td>0.979674</td>\n",
       "      <td>0.988346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(B, E)</td>\n",
       "      <td>[C, D]</td>\n",
       "      <td>0.981460</td>\n",
       "      <td>0.981410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(C, D)</td>\n",
       "      <td>[B, E]</td>\n",
       "      <td>0.990206</td>\n",
       "      <td>0.920024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(C, E)</td>\n",
       "      <td>[B, D]</td>\n",
       "      <td>0.989714</td>\n",
       "      <td>0.918250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(D, E)</td>\n",
       "      <td>[B, C]</td>\n",
       "      <td>0.998460</td>\n",
       "      <td>0.910649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(B, C, D)</td>\n",
       "      <td>[E]</td>\n",
       "      <td>0.978442</td>\n",
       "      <td>0.998965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(B, C, E)</td>\n",
       "      <td>[D]</td>\n",
       "      <td>0.978565</td>\n",
       "      <td>0.998004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(B, D, E)</td>\n",
       "      <td>[C]</td>\n",
       "      <td>0.986285</td>\n",
       "      <td>0.980117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(C, D, E)</td>\n",
       "      <td>[B]</td>\n",
       "      <td>0.993758</td>\n",
       "      <td>0.841944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_on    test_on  val_accuracy  test_accuracy\n",
       "0        (B,)  [C, D, E]      0.965016       0.977292\n",
       "1        (C,)  [B, D, E]      0.976718       0.943956\n",
       "2        (D,)  [B, C, E]      0.992486       0.939110\n",
       "3        (E,)  [B, C, D]      0.996674       0.933870\n",
       "4      (B, C)     [D, E]      0.967970       0.996354\n",
       "5      (B, D)     [C, E]      0.979674       0.988346\n",
       "6      (B, E)     [C, D]      0.981460       0.981410\n",
       "7      (C, D)     [B, E]      0.990206       0.920024\n",
       "8      (C, E)     [B, D]      0.989714       0.918250\n",
       "9      (D, E)     [B, C]      0.998460       0.910649\n",
       "10  (B, C, D)        [E]      0.978442       0.998965\n",
       "11  (B, C, E)        [D]      0.978565       0.998004\n",
       "12  (B, D, E)        [C]      0.986285       0.980117\n",
       "13  (C, D, E)        [B]      0.993758       0.841944"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804e062-d19c-480d-b633-6ee28fffda93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
