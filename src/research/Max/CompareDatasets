{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4c2146-1a43-41bd-bfda-034d3008bdc7",
   "metadata": {},
   "source": [
    "# Compare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8963ff5d-58bc-4ccd-88e6-6377ff6a2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Dict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import uniform, randint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba5be13-10ad-489e-89cb-139dc3abc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lengths_random(\n",
    "    dfs: Dict[str, pd.DataFrame],\n",
    "    random_state: int = 42\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For each DataFrame in dfs, sample down to the minimum length among them.\n",
    "\n",
    "    Args:\n",
    "        dfs: dict mapping names to DataFrames.\n",
    "        random_state: seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict of sampled DataFrames.\n",
    "    \"\"\"\n",
    "    min_len = min(len(df) for df in dfs.values())\n",
    "    print(f\"Sampling all datasets to {min_len} rows each (smallest dataset size)\")\n",
    "    return {\n",
    "        name: df.sample(n=min_len, random_state=random_state)\n",
    "                .reset_index(drop=True)\n",
    "        for name, df in dfs.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48771be-2c7f-4aed-919d-5bc76dc43bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset B: WELFake by Saurabh Shahane\n",
    "def load_B(path: str = \"../../data/Saurabh Shahane - Fake_News_Classification/WELFake_Dataset.csv\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    df = df.rename(columns={'Title': 'title', 'Text': 'text', 'Label': 'label'})\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "# Dataset C: Fake News by GonzaloA\n",
    "def load_C(\n",
    "    train_path: str = \"../../data/GonzaloA - fake_news/train_without_reuters.csv\",\n",
    "    val_path: str   = \"../../data/GonzaloA - fake_news/evaluation_without_reuters.csv\",\n",
    "    test_path: str  = \"../../data/GonzaloA - fake_news/test_without_reuters.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    parts = []\n",
    "    for p in [train_path, val_path, test_path]:\n",
    "        parts.append(\n",
    "            pd.read_csv(p,sep=';')\n",
    "        )\n",
    "    df = pd.concat(parts, ignore_index=True)\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'label'})\n",
    "    if 'content' in df.columns and 'text' not in df.columns:\n",
    "        df = df.rename(columns={'content': 'text'})\n",
    "        \n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "# Dataset D: fake-news-detection-dataset-English by ErfanMoosaviMonazzah\n",
    "def load_D(\n",
    "    train_path: str = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/train.tsv\",\n",
    "    val_path: str   = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/validation.tsv\",\n",
    "    test_path: str  = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/test.tsv\"\n",
    ") -> pd.DataFrame:\n",
    "    parts = [\n",
    "        pd.read_csv(train_path, sep='\\t', dtype=str),\n",
    "        pd.read_csv(val_path, sep='\\t', dtype=str),\n",
    "        pd.read_csv(test_path, sep='\\t', dtype=str)\n",
    "    ]\n",
    "    df = pd.concat(parts, ignore_index=True)\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "# Dataset E: Fake News Detection by Bhavik Jikadara\n",
    "def load_E(\n",
    "    fake_path: str = \"../../data/Bhavik Jikadara - Fake News Detection/fake.csv\",\n",
    "    real_path: str = \"../../data/Bhavik Jikadara - Fake News Detection/true.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    df_fake = pd.read_csv(fake_path, dtype=str)\n",
    "    df_real = pd.read_csv(real_path, dtype=str)\n",
    "    df_fake['label'] = '0'\n",
    "    df_real['label'] = '1'\n",
    "    df = pd.concat([df_fake, df_real], ignore_index=True)\n",
    "\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4bd4891-ec65-4069-b005-df86867f2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes rows where 'title' or 'text' is missing or empty.\n",
    "    \"\"\"\n",
    "    return df.dropna(subset=['title', 'text']).query(\"title != '' and text != ''\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9631ed8a-a8e9-4baa-b6cb-05f4626f6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_normalized(random_state: int = 42) -> Dict[str, pd.DataFrame]:\n",
    "    raw_dfs = {\n",
    "        'B': load_B(),\n",
    "        'C': load_C(),\n",
    "        'D': load_D(),\n",
    "        'E': load_E()\n",
    "    }\n",
    "\n",
    "    # Clean before normalization\n",
    "    cleaned_dfs = {name: clean_dataframe(df) for name, df in raw_dfs.items()}\n",
    "    return normalize_lengths_random(cleaned_dfs, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a71a88-ffc5-4247-b99d-1a57076283cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling all datasets to 40587 rows each (smallest dataset size)\n",
      "Dataset B: (40587, 3)\n",
      "Dataset C: (40587, 3)\n",
      "Dataset D: (40587, 3)\n",
      "Dataset E: (40587, 3)\n"
     ]
    }
   ],
   "source": [
    "    datasets = load_all_normalized()\n",
    "    for name, df in datasets.items():\n",
    "        print(f\"Dataset {name}:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbdbf38-7177-4420-941f-101e01659dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2912da0-95dd-49a5-9a0c-95a7bfe2bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = ['B', 'C', 'D', 'E']\n",
    "results = []\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2bc1c-0991-4372-a015-8756139d8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model on datasets: ('B',) | Testing on: ['C', 'D', 'E'] ===\n",
      "→ Training samples: 32469 | Test samples: 8118\n",
      "→ Starting training at 17:49:35\n",
      "Loaded model from models\\logreg_B.joblib\n",
      "→ Training complete at 17:49:36\n",
      "→ Duration: 0:00:00.191079\n",
      "→ Validation Accuracy: 0.9512\n",
      "\n",
      "=== Training model on datasets: ('C',) | Testing on: ['B', 'D', 'E'] ===\n",
      "→ Training samples: 32469 | Test samples: 8118\n",
      "→ Starting training at 17:50:28\n",
      "Trained and saved model to models\\logreg_C.joblib\n",
      "→ Training complete at 17:51:04\n",
      "→ Duration: 0:00:35.762229\n",
      "→ Validation Accuracy: 0.9670\n",
      "\n",
      "=== Training model on datasets: ('D',) | Testing on: ['B', 'C', 'E'] ===\n",
      "→ Training samples: 32469 | Test samples: 8118\n",
      "→ Starting training at 17:52:09\n",
      "Trained and saved model to models\\logreg_D.joblib\n",
      "→ Training complete at 17:52:42\n",
      "→ Duration: 0:00:32.793586\n",
      "→ Validation Accuracy: 0.9828\n",
      "\n",
      "=== Training model on datasets: ('E',) | Testing on: ['B', 'C', 'D'] ===\n",
      "→ Training samples: 32469 | Test samples: 8118\n",
      "→ Starting training at 17:53:45\n",
      "Trained and saved model to models\\logreg_E.joblib\n",
      "→ Training complete at 17:54:18\n",
      "→ Duration: 0:00:32.829085\n",
      "→ Validation Accuracy: 0.9879\n",
      "\n",
      "=== Training model on datasets: ('B', 'C') | Testing on: ['D', 'E'] ===\n",
      "→ Training samples: 64939 | Test samples: 16235\n",
      "→ Starting training at 17:55:22\n",
      "Trained and saved model to models\\logreg_B_C.joblib\n",
      "→ Training complete at 17:56:32\n",
      "→ Duration: 0:01:10.352574\n",
      "→ Validation Accuracy: 0.7137\n",
      "\n",
      "=== Training model on datasets: ('B', 'D') | Testing on: ['C', 'E'] ===\n",
      "→ Training samples: 64939 | Test samples: 16235\n",
      "→ Starting training at 17:57:17\n",
      "Trained and saved model to models\\logreg_B_D.joblib\n",
      "→ Training complete at 17:58:29\n",
      "→ Duration: 0:01:11.793268\n",
      "→ Validation Accuracy: 0.7130\n",
      "\n",
      "=== Training model on datasets: ('B', 'E') | Testing on: ['C', 'D'] ===\n",
      "→ Training samples: 64939 | Test samples: 16235\n",
      "→ Starting training at 17:59:17\n",
      "Trained and saved model to models\\logreg_B_E.joblib\n",
      "→ Training complete at 18:00:25\n",
      "→ Duration: 0:01:08.398921\n",
      "→ Validation Accuracy: 0.5890\n",
      "\n",
      "=== Training model on datasets: ('C', 'D') | Testing on: ['B', 'E'] ===\n",
      "→ Training samples: 64939 | Test samples: 16235\n",
      "→ Starting training at 18:01:09\n",
      "Trained and saved model to models\\logreg_C_D.joblib\n",
      "→ Training complete at 18:02:08\n",
      "→ Duration: 0:00:59.075436\n",
      "→ Validation Accuracy: 0.9821\n",
      "\n",
      "=== Training model on datasets: ('C', 'E') | Testing on: ['B', 'D'] ===\n",
      "→ Training samples: 64939 | Test samples: 16235\n",
      "→ Starting training at 18:02:58\n",
      "Trained and saved model to models\\logreg_C_E.joblib\n",
      "→ Training complete at 18:03:54\n",
      "→ Duration: 0:00:55.983326\n",
      "→ Validation Accuracy: 0.9828\n",
      "\n",
      "=== Training model on datasets: ('D', 'E') | Testing on: ['B', 'C'] ===\n",
      "→ Training samples: 64939 | Test samples: 16235\n",
      "→ Starting training at 18:04:46\n"
     ]
    }
   ],
   "source": [
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for r in range(1, len(all_sets)):\n",
    "    for combo in itertools.combinations(all_sets, r):        \n",
    "        model_name = '_'.join(combo)\n",
    "        model_path = Path(f\"models/logreg_{model_name}.joblib\")\n",
    "\n",
    "        df_trainval = pd.concat([datasets[d] for d in combo], ignore_index=True)\n",
    "        test_sets = [d for d in all_sets if d not in combo]\n",
    "        df_test = pd.concat([datasets[d] for d in test_sets], ignore_index=True)\n",
    "\n",
    "        X = df_trainval['title'] + '\\n' + df_trainval['text']\n",
    "        y = df_trainval['label']\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        print(f\"\\n=== Training model on datasets: {combo} | Testing on: {test_sets} ===\")\n",
    "        print(f\"→ Training samples: {X_train.shape[0]} | Test samples: {X_val.shape[0]}\")\n",
    "        start_time = datetime.now()\n",
    "        print(f\"→ Starting training at {start_time.strftime('%H:%M:%S')}\")\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', vectorizer),\n",
    "            ('clf', LogisticRegression(max_iter=1000))\n",
    "        ])\n",
    "\n",
    "        if model_path.exists():\n",
    "            pipeline = joblib.load(model_path)\n",
    "            print(f\"Loaded model from {model_path}\")\n",
    "        else:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            joblib.dump(pipeline, model_path)\n",
    "            print(f\"Trained and saved model to {model_path}\")\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        print(f\"→ Training complete at {end_time.strftime('%H:%M:%S')}\")\n",
    "        print(f\"→ Duration: {str(end_time - start_time)}\")\n",
    "\n",
    "        val_preds = pipeline.predict(X_val)\n",
    "        test_preds = pipeline.predict(df_test['title'] + '\\n' + df_test['text'])\n",
    "\n",
    "        val_acc = accuracy_score(y_val, val_preds)\n",
    "        test_acc = accuracy_score(df_test['label'], test_preds)\n",
    "        \n",
    "        print(f\"→ Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            'train_on': combo,\n",
    "            'test_on': test_sets,\n",
    "            'val_accuracy': val_acc,\n",
    "            'test_accuracy': test_acc\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e433b-a8ad-44ef-bbb7-adbd2c8e3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804e062-d19c-480d-b633-6ee28fffda93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
