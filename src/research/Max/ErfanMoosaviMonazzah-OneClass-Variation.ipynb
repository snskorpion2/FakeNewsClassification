{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d7ad9f",
   "metadata": {},
   "source": [
    "# One-Class Fake News Detection with Multiple Anomaly Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a56c5ce5-b093-4f65-948c-5bb84d87ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mager\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (1.72.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\mager\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\mager\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mager\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mager\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d64c490",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# Text feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# One-class models\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f78f30b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Paths and Data Loading\n",
    "train_path = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/train.tsv\"\n",
    "val_path   = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/validation.tsv\"\n",
    "test_path  = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/test.tsv\"\n",
    "\n",
    "# Read and sample 20% of each dataset\n",
    "df_train = pd.read_csv(train_path, sep='\\t', parse_dates=[\"date\"]).sample(frac=0.2, random_state=42)\n",
    "df_val   = pd.read_csv(val_path,   sep='\\t', parse_dates=[\"date\"]).sample(frac=0.2, random_state=42)\n",
    "df_test  = pd.read_csv(test_path,  sep='\\t', parse_dates=[\"date\"]).sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Merge title and text\n",
    "def merge_text(row):\n",
    "    return f\"{row['title']} \\n{row['text']}\"\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df['input_text'] = df.apply(merge_text, axis=1)\n",
    "\n",
    "# Prepare one-class training data (only real news)\n",
    "X_train = df_train.loc[df_train['label'] == 1, 'input_text']\n",
    "X_val, y_val = df_val['input_text'], df_val['label']\n",
    "X_test, y_test = df_test['input_text'], df_test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a62cafa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Vectorize text\n",
    "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec   = vectorizer.transform(X_val)\n",
    "X_test_vec  = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54aff7b8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "contamination = min(1 - df_train['label'].mean(), 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ceb7774",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def to_dense_if_needed(X):\n",
    "    return X.toarray() if issparse(X) else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "229e1ef8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def fit_model(name, model, X_train):\n",
    "    X_train = to_dense_if_needed(X_train)\n",
    "\n",
    "    if name == 'Autoencoder':\n",
    "        model.fit(X_train, X_train, epochs=10, batch_size=32, verbose=0)\n",
    "    elif name == 'GaussianMixture':\n",
    "        model.fit(X_train)\n",
    "    else:\n",
    "        model.fit(X_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15be1764",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_validation(name, model, X_val):\n",
    "    X_val = to_dense_if_needed(X_val)\n",
    "\n",
    "    if name == 'Autoencoder':\n",
    "        recon = model.predict(X_val)\n",
    "        mse = np.mean(np.power(X_val - recon, 2), axis=1)\n",
    "        threshold = np.percentile(mse, 80)\n",
    "        preds = (mse < threshold).astype(int)\n",
    "    elif name == 'GaussianMixture':\n",
    "        scores = model.score_samples(X_val)\n",
    "        threshold = np.percentile(scores, 20)\n",
    "        preds = (scores > threshold).astype(int)\n",
    "    else:\n",
    "        preds = model.predict(X_val)\n",
    "        preds = (preds == 1).astype(int)\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29b1ab21",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(name, preds, y_true):\n",
    "    print(f\"== {name} ==\")\n",
    "    print(classification_report(y_true, preds, target_names=[\"Fake\", \"Real\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b10c9da-0905-4079-b9b1-cee4d34ddadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== IsolationForest ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.47      0.44      0.45       589\n",
      "        Real       0.49      0.53      0.51       611\n",
      "\n",
      "    accuracy                           0.48      1200\n",
      "   macro avg       0.48      0.48      0.48      1200\n",
      "weighted avg       0.48      0.48      0.48      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_if = IsolationForest(n_estimators=100, contamination=contamination, random_state=42)\n",
    "model_if = fit_model('IsolationForest', model_if, X_train_vec)\n",
    "preds_if = predict_validation('IsolationForest', model_if, X_val_vec)\n",
    "evaluate_model('IsolationForest', preds_if, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa2e3e2-cd60-488c-95e8-53874a483ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== OneClassSVM ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.57      0.92      0.71       589\n",
      "        Real       0.81      0.34      0.48       611\n",
      "\n",
      "    accuracy                           0.62      1200\n",
      "   macro avg       0.69      0.63      0.59      1200\n",
      "weighted avg       0.69      0.62      0.59      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "model_ocsvm = OneClassSVM(kernel='rbf', gamma='auto', nu=contamination)\n",
    "model_ocsvm = fit_model('OneClassSVM', model_ocsvm, X_train_vec)\n",
    "preds_ocsvm = predict_validation('OneClassSVM', model_ocsvm, X_val_vec)\n",
    "evaluate_model('OneClassSVM', preds_ocsvm, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17b9964f-d21b-491e-b18c-4d2ed89f24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== LocalOutlierFactor ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.63      0.84      0.72       589\n",
      "        Real       0.78      0.52      0.62       611\n",
      "\n",
      "    accuracy                           0.68      1200\n",
      "   macro avg       0.70      0.68      0.67      1200\n",
      "weighted avg       0.70      0.68      0.67      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "model_lof = LocalOutlierFactor(n_neighbors=20, contamination=contamination, novelty=True)\n",
    "model_lof = fit_model('LocalOutlierFactor', model_lof, X_train_vec)\n",
    "preds_lof = predict_validation('LocalOutlierFactor', model_lof, X_val_vec)\n",
    "evaluate_model('LocalOutlierFactor', preds_lof, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd45bcc5-0905-4855-9d1c-89c640fc2090",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 437. MiB for an array with shape (2863, 20000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Fit PCA on dense TF‑IDF\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_train_dense \u001b[38;5;241m=\u001b[39m to_dense_if_needed(X_train_vec)\n\u001b[0;32m      5\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m pca\u001b[38;5;241m.\u001b[39mfit(X_train_dense)\n",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m, in \u001b[0;36mto_dense_if_needed\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dense_if_needed\u001b[39m(X):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1106\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1106\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:1327\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 437. MiB for an array with shape (2863, 20000) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1. Fit PCA on dense TF‑IDF\n",
    "X_train_dense = to_dense_if_needed(X_train_vec)\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "pca.fit(X_train_dense)\n",
    "\n",
    "# 2. Compute reconstruction error on validation\n",
    "X_val_dense = to_dense_if_needed(X_val_vec)\n",
    "X_val_rec   = pca.inverse_transform(pca.transform(X_val_dense))\n",
    "mse_val     = np.mean((X_val_dense - X_val_rec)**2, axis=1)\n",
    "\n",
    "# 3. Threshold (e.g. bottom 80% = inliers)\n",
    "thresh_pca  = np.percentile(mse_val, 80)\n",
    "preds_pca   = (mse_val < thresh_pca).astype(int)\n",
    "\n",
    "# 4. Evaluate\n",
    "evaluate_model('PCA Reconstruction', preds_pca, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69ed7d34-4815-43f6-a5a2-fd961ab59402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== KNN Distance ==\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.89      0.36      0.52       589\n",
      "        Real       0.61      0.96      0.74       611\n",
      "\n",
      "    accuracy                           0.67      1200\n",
      "   macro avg       0.75      0.66      0.63      1200\n",
      "weighted avg       0.75      0.67      0.63      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# 1. Fit KNN on dense TF‑IDF\n",
    "X_train_dense = to_dense_if_needed(X_train_vec)\n",
    "knn = NearestNeighbors(n_neighbors=5)\n",
    "knn.fit(X_train_dense)\n",
    "\n",
    "# 2. Compute avg dist to 5 neighbors for validation\n",
    "X_val_dense = to_dense_if_needed(X_val_vec)\n",
    "distances, _ = knn.kneighbors(X_val_dense)\n",
    "avg_dist = distances.mean(axis=1)\n",
    "\n",
    "# 3. Threshold (e.g. bottom 80% of distances considered inlier)\n",
    "thresh_knn = np.percentile(avg_dist, 80)\n",
    "preds_knn  = (avg_dist < thresh_knn).astype(int)\n",
    "\n",
    "# 4. Evaluate\n",
    "evaluate_model('KNN Distance', preds_knn, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ada98c-ab13-4958-ac2a-f098eb2f5b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696cb0b1-9b95-49e7-adb6-62ae10601315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46627a-45a7-4700-91c4-49e3a0e1bb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
