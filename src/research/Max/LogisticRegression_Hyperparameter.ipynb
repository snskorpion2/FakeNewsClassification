{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4c2146-1a43-41bd-bfda-034d3008bdc7",
   "metadata": {},
   "source": [
    "# Logistische Regression - hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8963ff5d-58bc-4ccd-88e6-6377ff6a2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba5be13-10ad-489e-89cb-139dc3abc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/train.tsv\"\n",
    "val_path   = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/validation.tsv\"\n",
    "test_path  = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/test.tsv\"\n",
    "\n",
    "# Reading with tab separator and parsing dates\n",
    "df_train = pd.read_csv(train_path, sep='\\t', parse_dates=[\"date\"], dayfirst=False)\n",
    "df_val   = pd.read_csv(val_path,   sep='\\t', parse_dates=[\"date\"], dayfirst=False)\n",
    "df_test  = pd.read_csv(test_path,  sep='\\t', parse_dates=[\"date\"], dayfirst=False)\n",
    "\n",
    "# Merge title and text into a single input text\n",
    "def merge_text(row):\n",
    "    return f\"{row['title']} \\n{row['text']}\"\n",
    "\n",
    "for df in (df_train, df_val, df_test):\n",
    "    df['input_text'] = df.apply(merge_text, axis=1)\n",
    "\n",
    "X_train, y_train = df_train['input_text'], df_train['label']\n",
    "X_val,   y_val   = df_val['input_text'],   df_val['label']\n",
    "X_test,  y_test  = df_test['input_text'],  df_test['label']  # For final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48771be-2c7f-4aed-919d-5bc76dc43bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring full HalvingRandomSearchCV with ~162 initial candidates\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(solver='saga', max_iter=5000, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_distributions = [\n",
    "    {\n",
    "        'tfidf__max_features': randint(5000, 20001),\n",
    "        'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "        'tfidf__min_df': randint(1, 6),\n",
    "        'tfidf__max_df': uniform(0.8, 0.2),\n",
    "        'tfidf__stop_words': [None, 'english'],\n",
    "        'clf__penalty': ['l2', 'l1'],\n",
    "        'clf__C': uniform(0.01, 10),\n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__l1_ratio': [None]\n",
    "    },\n",
    "    {\n",
    "        'tfidf__max_features': randint(5000, 20001),\n",
    "        'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "        'tfidf__min_df': randint(1, 6),\n",
    "        'tfidf__max_df': uniform(0.8, 0.2),\n",
    "        'tfidf__stop_words': [None, 'english'],\n",
    "        'clf__penalty': ['elasticnet'],\n",
    "        'clf__C': uniform(0.01, 10),\n",
    "        'clf__l1_ratio': uniform(0, 1),\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define halving search (full run) with adjusted number of candidates to fit ~60x pilot time\n",
    "n_pilot_cand = 9\n",
    "pilot_frac = 0.3\n",
    "scale_factor = 1 / pilot_frac  # ≈3.33\n",
    "# To spend ~60× the pilot time: n_full_cand ≈ 60 * n_pilot_cand / scale_factor\n",
    "n_full_candidates = int(60 * n_pilot_cand / scale_factor)\n",
    "print(f\"Configuring full HalvingRandomSearchCV with ~{n_full_candidates} initial candidates\")  # for sanity check\n",
    "\n",
    "halving_search_full = HalvingRandomSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_candidates=n_full_candidates,\n",
    "    factor=3,\n",
    "    resource='n_samples',\n",
    "    max_resources=len(X_train),\n",
    "    min_resources=len(X_train) // 10,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    return_train_score=True,\n",
    "    error_score='raise'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1115396-4448-426b-99b9-f026c81a1485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 3000\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 162\n",
      "n_resources: 3000\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    }
   ],
   "source": [
    "halving_search_full.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", halving_search.best_params_)\n",
    "print(f\"Best cross-validation accuracy: {halving_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a71a88-ffc5-4247-b99d-1a57076283cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = halving_search_full.best_estimator_\n",
    "val_preds = best_model.predict(X_val)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
    "print(classification_report(y_val, val_preds, target_names=['Real', 'Fake']))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbdbf38-7177-4420-941f-101e01659dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = best_model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\n",
    "print(classification_report(y_test, test_preds, target_names=['Real', 'Fake']))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab3c1b-5e92-46e4-b9c3-332e77d5f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, 'best_fake_news_detector_halving_random_search.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9eba9-fcca-436c-b93a-69bc0a303baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
