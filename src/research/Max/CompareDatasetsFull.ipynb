{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4c2146-1a43-41bd-bfda-034d3008bdc7",
   "metadata": {},
   "source": [
    "# Compare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8963ff5d-58bc-4ccd-88e6-6377ff6a2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Dict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import uniform, randint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5be13-10ad-489e-89cb-139dc3abc53f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48771be-2c7f-4aed-919d-5bc76dc43bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset B: WELFake by Saurabh Shahane\n",
    "def load_B(path: str = \"../../data/Saurabh Shahane - Fake_News_Classification/WELFake_Dataset.csv\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'Title': 'title', 'Text': 'text', 'Label': 'label'})\n",
    "    df['label'] = 1 - df['label'].astype(int)  # Flip labels: 0 → 1, 1 → 0\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "\n",
    "# Dataset C: Fake News by GonzaloA\n",
    "def load_C(\n",
    "    train_path: str = \"../../data/GonzaloA - fake_news/train_without_reuters.csv\",\n",
    "    val_path: str   = \"../../data/GonzaloA - fake_news/evaluation_without_reuters.csv\",\n",
    "    test_path: str  = \"../../data/GonzaloA - fake_news/test_without_reuters.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    parts = []\n",
    "    for p in [train_path, val_path, test_path]:\n",
    "        parts.append(\n",
    "            pd.read_csv(p,sep=';')\n",
    "        )\n",
    "    df = pd.concat(parts, ignore_index=True)\n",
    "    if 'value' in df.columns:\n",
    "        df = df.rename(columns={'value': 'label'})\n",
    "    if 'content' in df.columns and 'text' not in df.columns:\n",
    "        df = df.rename(columns={'content': 'text'})\n",
    "        \n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "# Dataset D: fake-news-detection-dataset-English by ErfanMoosaviMonazzah\n",
    "def load_D(\n",
    "    train_path: str = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/train.tsv\",\n",
    "    val_path: str   = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/validation.tsv\",\n",
    "    test_path: str  = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/test.tsv\"\n",
    ") -> pd.DataFrame:\n",
    "    parts = [\n",
    "        pd.read_csv(train_path, sep='\\t', dtype=str),\n",
    "        pd.read_csv(val_path, sep='\\t', dtype=str),\n",
    "        pd.read_csv(test_path, sep='\\t', dtype=str)\n",
    "    ]\n",
    "    df = pd.concat(parts, ignore_index=True)\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]\n",
    "\n",
    "# Dataset E: Fake News Detection by Bhavik Jikadara\n",
    "def load_E(\n",
    "    fake_path: str = \"../../data/Bhavik Jikadara - Fake News Detection/fake.csv\",\n",
    "    real_path: str = \"../../data/Bhavik Jikadara - Fake News Detection/true.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    df_fake = pd.read_csv(fake_path, dtype=str)\n",
    "    df_real = pd.read_csv(real_path, dtype=str)\n",
    "    df_fake['label'] = '0'\n",
    "    df_real['label'] = '1'\n",
    "    df = pd.concat([df_fake, df_real], ignore_index=True)\n",
    "\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    return df[['title', 'text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bd4891-ec65-4069-b005-df86867f2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes rows where 'title' or 'text' is missing or empty.\n",
    "    \"\"\"\n",
    "    return df.dropna(subset=['title', 'text']).query(\"title != '' and text != ''\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631ed8a-a8e9-4baa-b6cb-05f4626f6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_full() -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads datasets B, C, D, and E in their entirety.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'B': load_B(),\n",
    "        'C': load_C(),\n",
    "        'D': load_D(),\n",
    "        'E': load_E()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a71a88-ffc5-4247-b99d-1a57076283cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset B: (71537, 3)\n",
      "Dataset C: (40587, 3)\n",
      "Dataset D: (44267, 3)\n",
      "Dataset E: (44898, 3)\n"
     ]
    }
   ],
   "source": [
    "    raw_dfs = load_all_full()\n",
    "\n",
    "    datasets = {name: clean_dataframe(df) for name, df in raw_dfs.items()}\n",
    "    for name, df in datasets.items():\n",
    "        print(f\"Dataset {name}:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbdbf38-7177-4420-941f-101e01659dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2912da0-95dd-49a5-9a0c-95a7bfe2bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sets = ['B', 'C', 'D', 'E']\n",
    "results = []\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef2bc1c-0991-4372-a015-8756139d8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model on datasets: ('B',) | Testing on: ['C', 'D', 'E'] ===\n",
      "Loaded model from models\\logreg_B.joblib\n",
      "→ Duration: 0:00:00.102152\n",
      "→ Validation Accuracy: 0.9770\n",
      "\n",
      "=== Training model on datasets: ('C',) | Testing on: ['B', 'D', 'E'] ===\n",
      "Loaded model from models\\logreg_C.joblib\n",
      "→ Duration: 0:00:00.104307\n",
      "→ Validation Accuracy: 0.9925\n",
      "\n",
      "=== Training model on datasets: ('D',) | Testing on: ['B', 'C', 'E'] ===\n",
      "Loaded model from models\\logreg_D.joblib\n",
      "→ Duration: 0:00:00.107388\n",
      "→ Validation Accuracy: 0.9967\n",
      "\n",
      "=== Training model on datasets: ('E',) | Testing on: ['B', 'C', 'D'] ===\n",
      "Loaded model from models\\logreg_E.joblib\n",
      "→ Duration: 0:00:00.098202\n",
      "→ Validation Accuracy: 0.9988\n",
      "\n",
      "=== Training model on datasets: ('B', 'C') | Testing on: ['D', 'E'] ===\n",
      "Loaded model from models\\logreg_B_C.joblib\n",
      "→ Duration: 0:00:00.101757\n",
      "→ Validation Accuracy: 0.9805\n",
      "\n",
      "=== Training model on datasets: ('B', 'D') | Testing on: ['C', 'E'] ===\n",
      "Loaded model from models\\logreg_B_D.joblib\n",
      "→ Duration: 0:00:00.098241\n",
      "→ Validation Accuracy: 0.9859\n",
      "\n",
      "=== Training model on datasets: ('B', 'E') | Testing on: ['C', 'D'] ===\n",
      "Loaded model from models\\logreg_B_E.joblib\n",
      "→ Duration: 0:00:00.107963\n",
      "→ Validation Accuracy: 0.9870\n",
      "\n",
      "=== Training model on datasets: ('C', 'D') | Testing on: ['B', 'E'] ===\n",
      "Loaded model from models\\logreg_C_D.joblib\n",
      "→ Duration: 0:00:00.094587\n",
      "→ Validation Accuracy: 0.9961\n",
      "\n",
      "=== Training model on datasets: ('C', 'E') | Testing on: ['B', 'D'] ===\n",
      "Loaded model from models\\logreg_C_E.joblib\n",
      "→ Duration: 0:00:00.104788\n",
      "→ Validation Accuracy: 0.9964\n",
      "\n",
      "=== Training model on datasets: ('D', 'E') | Testing on: ['B', 'C'] ===\n",
      "Loaded model from models\\logreg_D_E.joblib\n",
      "→ Duration: 0:00:00.108204\n",
      "→ Validation Accuracy: 0.9991\n",
      "\n",
      "=== Training model on datasets: ('B', 'C', 'D') | Testing on: ['E'] ===\n",
      "Loaded model from models\\logreg_B_C_D.joblib\n",
      "→ Duration: 0:00:00.103980\n",
      "→ Validation Accuracy: 0.9856\n",
      "\n",
      "=== Training model on datasets: ('B', 'C', 'E') | Testing on: ['D'] ===\n",
      "Loaded model from models\\logreg_B_C_E.joblib\n",
      "→ Duration: 0:00:00.104092\n",
      "→ Validation Accuracy: 0.9856\n",
      "\n",
      "=== Training model on datasets: ('B', 'D', 'E') | Testing on: ['C'] ===\n",
      "Loaded model from models\\logreg_B_D_E.joblib\n",
      "→ Duration: 0:00:00.109042\n",
      "→ Validation Accuracy: 0.9887\n",
      "\n",
      "=== Training model on datasets: ('C', 'D', 'E') | Testing on: ['B'] ===\n",
      "Loaded model from models\\logreg_C_D_E.joblib\n",
      "→ Duration: 0:00:00.106127\n",
      "→ Validation Accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for r in range(1, len(all_sets)):\n",
    "    for combo in itertools.combinations(all_sets, r):        \n",
    "        model_name = '_'.join(combo)\n",
    "        model_path = Path(f\"models/logreg_{model_name}.joblib\")\n",
    "\n",
    "        df_trainval = pd.concat([datasets[d] for d in combo], ignore_index=True)\n",
    "        test_sets = [d for d in all_sets if d not in combo]\n",
    "        df_test = pd.concat([datasets[d] for d in test_sets], ignore_index=True)\n",
    "\n",
    "        X = df_trainval['title'] + '\\n' + df_trainval['text']\n",
    "        y = df_trainval['label']\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        print(f\"\\n=== Training model on datasets: {combo} | Testing on: {test_sets} ===\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                max_features=13954,\n",
    "                ngram_range=(1, 2),\n",
    "                stop_words=None,\n",
    "                max_df=0.8891916614020643,\n",
    "                min_df=3\n",
    "            )),\n",
    "            ('clf', LogisticRegression(\n",
    "                C=8.725368061523762,\n",
    "                class_weight='balanced',\n",
    "                penalty='elasticnet',\n",
    "                l1_ratio=0.6760522571867544,\n",
    "                solver='saga',\n",
    "                max_iter=1000\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        if model_path.exists():\n",
    "            pipeline = joblib.load(model_path)\n",
    "            print(f\"Loaded model from {model_path}\")\n",
    "        else:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            joblib.dump(pipeline, model_path)\n",
    "            print(f\"Trained and saved model to {model_path}\")\n",
    "\n",
    "        end_time = datetime.now()\n",
    "        print(f\"→ Duration: {str(end_time - start_time)}\")\n",
    "\n",
    "        val_preds = pipeline.predict(X_val)\n",
    "        test_preds = pipeline.predict(df_test['title'] + '\\n' + df_test['text'])\n",
    "\n",
    "        val_acc = accuracy_score(y_val, val_preds)\n",
    "        test_acc = accuracy_score(df_test['label'], test_preds)\n",
    "        \n",
    "        print(f\"→ Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            'train_on': combo,\n",
    "            'test_on': test_sets,\n",
    "            'val_accuracy': val_acc,\n",
    "            'test_accuracy': test_acc\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da0e433b-a8ad-44ef-bbb7-adbd2c8e3f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_on</th>\n",
       "      <th>test_on</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(B,)</td>\n",
       "      <td>[C, D, E]</td>\n",
       "      <td>0.977006</td>\n",
       "      <td>0.977773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(C,)</td>\n",
       "      <td>[B, D, E]</td>\n",
       "      <td>0.992486</td>\n",
       "      <td>0.926454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(D,)</td>\n",
       "      <td>[B, C, E]</td>\n",
       "      <td>0.996725</td>\n",
       "      <td>0.921693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(E,)</td>\n",
       "      <td>[B, C, D]</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.915878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(B, C)</td>\n",
       "      <td>[D, E]</td>\n",
       "      <td>0.980513</td>\n",
       "      <td>0.996378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(B, D)</td>\n",
       "      <td>[C, E]</td>\n",
       "      <td>0.985881</td>\n",
       "      <td>0.988817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(B, E)</td>\n",
       "      <td>[C, D]</td>\n",
       "      <td>0.987031</td>\n",
       "      <td>0.981733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(C, D)</td>\n",
       "      <td>[B, E]</td>\n",
       "      <td>0.996111</td>\n",
       "      <td>0.901679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(C, E)</td>\n",
       "      <td>[B, D]</td>\n",
       "      <td>0.996374</td>\n",
       "      <td>0.899762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(D, E)</td>\n",
       "      <td>[B, C]</td>\n",
       "      <td>0.999103</td>\n",
       "      <td>0.891682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(B, C, D)</td>\n",
       "      <td>[E]</td>\n",
       "      <td>0.985613</td>\n",
       "      <td>0.998998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(B, C, E)</td>\n",
       "      <td>[D]</td>\n",
       "      <td>0.985576</td>\n",
       "      <td>0.998035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(B, D, E)</td>\n",
       "      <td>[C]</td>\n",
       "      <td>0.988737</td>\n",
       "      <td>0.980117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(C, D, E)</td>\n",
       "      <td>[B]</td>\n",
       "      <td>0.997148</td>\n",
       "      <td>0.842375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_on    test_on  val_accuracy  test_accuracy\n",
       "0        (B,)  [C, D, E]      0.977006       0.977773\n",
       "1        (C,)  [B, D, E]      0.992486       0.926454\n",
       "2        (D,)  [B, C, E]      0.996725       0.921693\n",
       "3        (E,)  [B, C, D]      0.998775       0.915878\n",
       "4      (B, C)     [D, E]      0.980513       0.996378\n",
       "5      (B, D)     [C, E]      0.985881       0.988817\n",
       "6      (B, E)     [C, D]      0.987031       0.981733\n",
       "7      (C, D)     [B, E]      0.996111       0.901679\n",
       "8      (C, E)     [B, D]      0.996374       0.899762\n",
       "9      (D, E)     [B, C]      0.999103       0.891682\n",
       "10  (B, C, D)        [E]      0.985613       0.998998\n",
       "11  (B, C, E)        [D]      0.985576       0.998035\n",
       "12  (B, D, E)        [C]      0.988737       0.980117\n",
       "13  (C, D, E)        [B]      0.997148       0.842375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804e062-d19c-480d-b633-6ee28fffda93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
