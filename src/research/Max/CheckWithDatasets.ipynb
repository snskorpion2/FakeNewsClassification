{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8bc050-bcd2-4a7a-b58c-ad42b71bdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62a8f44-459b-48d5-8268-a9dbf4014379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_datasets(basepath):\n",
    "    \"\"\"\n",
    "    Load and clean individual fake news datasets from subfolders in basepath.\n",
    "    Returns a dict of pandas DataFrames keyed by dataset name.\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "\n",
    "    # 1. Aadya Singh_Fakenews: evaluation.csv, test (1).csv, train (2).csv\n",
    "    folder = os.path.join(basepath, \"Aadya Singh  _fake-and_real_news\")\n",
    "    files = [\"evaluation.csv\", \"test (1).csv\", \"train (2).csv\"]\n",
    "    dfs = [pd.read_csv(os.path.join(folder, f), sep=';') for f in files]\n",
    "    datasets['Aadya_Singh'] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 2. Bhavik Jikadara - Fake News Detection\n",
    "    folder = os.path.join(basepath, \"Bhavik Jikadara - Fake News Detection\")\n",
    "    fake = pd.read_csv(os.path.join(folder, \"fake.csv\"))\n",
    "    true = pd.read_csv(os.path.join(folder, \"true.csv\"))\n",
    "    # Assign labels\n",
    "    fake['label'] = 0   # fake → 0\n",
    "    true['label'] = 1   # real → 1\n",
    "    datasets['Bhavik_Jikadara'] = pd.concat([fake, true], ignore_index=True)\n",
    "\n",
    "    # 3. clmentbisaillon_Fakenews\n",
    "    folder = os.path.join(basepath, \"clmentbisaillon_Fakenews\")\n",
    "    real = pd.read_csv(os.path.join(folder, \"True.csv\"))\n",
    "    fake = pd.read_csv(os.path.join(folder, \"Fake.csv\"))\n",
    "    # Drop placeholder empty texts\n",
    "    if 'text' in real.columns:\n",
    "        real = real[real['text'] != \"[empty]\"]\n",
    "    if 'text' in fake.columns:\n",
    "        fake = fake[fake['text'] != \"[empty]\"]\n",
    "    # Assign labels\n",
    "    real['label'] = 1   # real → 1\n",
    "    fake['label'] = 0   # fake → 0\n",
    "    df3 = pd.concat([real, fake], ignore_index=True)\n",
    "    datasets['clmentbisaillon'] = df3\n",
    "\n",
    "    # 4. ErfanMoosaviMonazzah - fake-news-detection-dataset-English\n",
    "    folder = os.path.join(basepath, \"ErfanMoosaviMonazzah - fake-news-detection-dataset-English\")\n",
    "    parts = [\"test.tsv\", \"train.tsv\", \"validation.tsv\"]\n",
    "    dfs = [pd.read_csv(os.path.join(folder, p), sep='\\t') for p in parts]\n",
    "    datasets['ErfanMoosaviMonazzah'] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 5. GonzaloA - fake_news\n",
    "    folder = os.path.join(basepath, \"GonzaloA - fake_news\")\n",
    "    parts = [\"test.csv\", \"train.csv\", \"evaluation.csv\"]\n",
    "    dfs = [pd.read_csv(os.path.join(folder, p), sep=';') for p in parts]\n",
    "    datasets['GonzaloA'] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # 6. Hassan Amin - fake_or_real_news.csv\n",
    "    df6 = pd.read_csv(\n",
    "        os.path.join(basepath, \"Hassan Amin-fake_or_real_news.csv/fake_or_real_news.csv\")\n",
    "    )\n",
    "\n",
    "    # The column in this file is likely named 'label' or 'type'; adjust as needed:\n",
    "    # Map the textual labels to integers\n",
    "    df6['label'] = df6['label'].str.upper().map({\n",
    "        'FAKE': 0,\n",
    "        'REAL': 1\n",
    "    })\n",
    "\n",
    "    datasets['Hassan_Amin'] = df6\n",
    "\n",
    "    # 7. Meg Risdal_fake_only\n",
    "    folder = os.path.join(basepath, \"Meg Risdal_fake_only\")\n",
    "    df7 = pd.read_csv(os.path.join(folder, \"fake.csv\"))\n",
    "    # Drop null titles and non‑English entries\n",
    "    if 'titel' in df7.columns:\n",
    "        df7 = df7.dropna(subset=['titel'])\n",
    "        df7 = df7.rename(columns={'titel': 'title'})\n",
    "    if 'language' in df7.columns:\n",
    "        df7 = df7[df7['language'].str.lower() == 'english']\n",
    "    # Assign label: fake-only → 0\n",
    "    df7['label'] = 0\n",
    "    df7 = df7.dropna(subset=['title', 'text'])\n",
    "    df7 = df7[(df7['title'].str.strip() != '') & (df7['text'].str.strip() != '')]\n",
    "    datasets['Meg_Risdal'] = df7\n",
    "\n",
    "    # 8. Ruchi Bhatia_news_articles.csv\n",
    "    df8 = pd.read_csv(os.path.join(basepath, \"Ruchi Bhatia_news_articles.csv/news_articles.csv\"))\n",
    "    # Clean entries\n",
    "    df8 = df8[~df8['title'].str.lower().isin(['no title', 'newsticker'])]\n",
    "    df8 = df8[df8['text'].notna()]\n",
    "    if 'language' in df8.columns:\n",
    "        df8 = df8[df8['language'].str.lower() == 'english']\n",
    "    df8['label'] = df8['label'].str.upper().map({\n",
    "        'Fake': 0,\n",
    "        'Real': 1\n",
    "    })\n",
    "    datasets['Ruchi_Bhatia'] = df8\n",
    "\n",
    "    # 9. Saurabh Shahane - Fake_News_Classification\n",
    "    datasets['Saurabh_Shahane'] = pd.read_csv(\n",
    "        os.path.join(basepath, \"Saurabh Shahane - Fake_News_Classification\", \"WELFake_Dataset.csv\")\n",
    "    )\n",
    "\n",
    "    # 10. andyP/fake_news_en_opensources\n",
    "    #df10 = pd.read_csv(\n",
    "    #    os.path.join(basepath, \"bigFakeNews\", \"opensources_fake_news_cleaned.csv\")\n",
    "    #)\n",
    "    \n",
    "    # Keep only 'reliable' and 'fake' types\n",
    "    #df10 = df10[df10['type'].isin(['reliable', 'fake'])]\n",
    "    \n",
    "    # Add 'label' column: 1 for reliable, 0 for fake\n",
    "    #df10['label'] = df10['type'].map({'reliable': 1, 'fake': 0})\n",
    "    \n",
    "    # Rename 'content' column to 'text'\n",
    "    #df10.rename(columns={'content': 'text'}, inplace=True)\n",
    "    \n",
    "    # Store in datasets dictionary\n",
    "    #datasets['andyP_opensources'] = df10\n",
    "\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57fcda8e-dcfc-496b-827e-fe88ae990e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model trained on C+D+E\n",
    "model_path = \"./models/logreg_B_C_D.joblib\"\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5043ff76-716c-4bc3-8ecd-89bcf98099f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets fully\n",
    "base_path = '../../data'\n",
    "datasets = load_datasets(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3c4427-a8a4-4d8a-8b4a-68c4d06a66de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model logreg_C_D_E.joblib on individual datasets:\n",
      "\n",
      "Dataset Aadya_Singh: accuracy = 0.99250992\n",
      "Dataset Bhavik_Jikadara: accuracy = 0.99973273\n",
      "Dataset clmentbisaillon: accuracy = 0.99973273\n",
      "Dataset ErfanMoosaviMonazzah: accuracy = 0.99959338\n",
      "Dataset GonzaloA: accuracy = 0.99250992\n",
      "Dataset Hassan_Amin: accuracy = 0.57663773\n",
      "Dataset Meg_Risdal: accuracy = 0.87362780\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=['Fake' 'Real'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:131\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m _union1d(y_true, y_pred, xp)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:184\u001b[0m, in \u001b[0;36m_union1d\u001b[1;34m(a, b, xp)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(numpy\u001b[38;5;241m.\u001b[39munion1d(a, b))\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m b\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:932\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03mFind the union of two arrays.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;124;03marray([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unique(np\u001b[38;5;241m.\u001b[39mconcatenate((ar1, ar2), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m----> 7\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y, y_pred)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:137\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    131\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m _union1d(y_true, y_pred, xp)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot y_true=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxp\u001b[38;5;241m.\u001b[39munique(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxp\u001b[38;5;241m.\u001b[39munique(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure that the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions provided by the classifier coincides with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe true labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    145\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=['Fake' 'Real'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    }
   ],
   "source": [
    "# Evaluate on each dataset individually\n",
    "print(\"Evaluating model logreg_C_D_E.joblib on individual datasets:\\n\")\n",
    "for name, df in datasets.items():\n",
    "    X = df['title'] + '\\n' + df['text']\n",
    "    y = df['label']\n",
    "    y_pred = model.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    print(f\"Dataset {name}: accuracy = {acc:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e27d20-887d-4c7f-a2cd-cec1c4a80f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
