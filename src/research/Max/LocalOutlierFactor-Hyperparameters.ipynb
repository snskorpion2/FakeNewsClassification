{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dba5b80",
   "metadata": {},
   "source": [
    "# One-Class Fake News Classification with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c39f922a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Train/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# One-class classifier and evaluation metrics\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Pipeline utilities\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5b6155",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Paths to dataset splits\n",
    "train_path = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/train.tsv\"\n",
    "val_path   = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/validation.tsv\"\n",
    "test_path  = \"../../data/ErfanMoosaviMonazzah - fake-news-detection-dataset-English/test.tsv\"\n",
    "\n",
    "# Read datasets\n",
    "df_train = pd.read_csv(train_path, sep='\\t', parse_dates=[\"date\"], dayfirst=False)\n",
    "df_val   = pd.read_csv(val_path,   sep='\\t', parse_dates=[\"date\"], dayfirst=False)\n",
    "df_test  = pd.read_csv(test_path,  sep='\\t', parse_dates=[\"date\"], dayfirst=False)\n",
    "\n",
    "# Merge title and text into a single feature\n",
    "def merge_text(row):\n",
    "    return f\"{row['title']} \\n{row['text']}\"\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df['input_text'] = df.apply(merge_text, axis=1)\n",
    "\n",
    "# Prepare data splits\n",
    "X_train_raw, y_train = df_train['input_text'], df_train['label']\n",
    "X_val_raw,   y_val   = df_val['input_text'],   df_val['label']\n",
    "X_test_raw,  y_test  = df_test['input_text'],  df_test['label']\n",
    "\n",
    "X_train_real_raw = X_train_raw[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf218ecf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# 3) Define grid\n",
    "param_grid = {\n",
    "    'tfidf__max_features': [5_000, 10_000, 20_000],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)],\n",
    "    'lof__n_neighbors'   : [5, 10, 20],\n",
    "    'lof__contamination' : [0.01, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5206871-ac69-409e-a28e-8abb0c340e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_lof_params(params):\n",
    "    # build vectorizer + LOF\n",
    "    vec = TfidfVectorizer(\n",
    "        max_features=params['tfidf__max_features'],\n",
    "        ngram_range=params['tfidf__ngram_range'],\n",
    "        stop_words='english'\n",
    "    )\n",
    "    lof = LocalOutlierFactor(\n",
    "        n_neighbors=params['lof__n_neighbors'],\n",
    "        contamination=params['lof__contamination'],\n",
    "        novelty=True\n",
    "    )\n",
    "    # FIT on real-only data\n",
    "    Xtr = vec.fit_transform(X_train_real_raw)\n",
    "    lof.fit(Xtr.toarray())\n",
    "    \n",
    "    # EVAL on mixed val set\n",
    "    Xv = vec.transform(X_val_raw)\n",
    "    raw = lof.predict(Xv.toarray())        # +1=inlier (real), -1=outlier (fake)\n",
    "    y_pred = np.where(raw == 1, 1, 0)\n",
    "    \n",
    "    return accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69fc440",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5) bruteâ€force search\n",
    "best_score  = -1\n",
    "best_params = None\n",
    "total = np.prod([len(v) for v in param_grid.values()])\n",
    "i = 0\n",
    "\n",
    "for mf in param_grid['tfidf__max_features']:\n",
    "    for ngr in param_grid['tfidf__ngram_range']:\n",
    "        for nn in param_grid['lof__n_neighbors']:\n",
    "            for cont in param_grid['lof__contamination']:\n",
    "                i += 1\n",
    "                p = {\n",
    "                    'tfidf__max_features': mf,\n",
    "                    'tfidf__ngram_range': ngr,\n",
    "                    'lof__n_neighbors': nn,\n",
    "                    'lof__contamination': cont\n",
    "                }\n",
    "                score = evaluate_lof_params(p)\n",
    "                print(f\"[{i}/{total}] {p} â†’ Val acc: {score:.4f}\")\n",
    "                if score > best_score:\n",
    "                    best_score, best_params = score, p.copy()\n",
    "\n",
    "print(\"\\nâœ… Best validation accuracy:\", best_score)\n",
    "print(\"ðŸ“‹ Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80f6f54a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.23 GiB for an array with shape (8267, 20000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Transform and predict on test data\u001b[39;00m\n\u001b[0;32m     29\u001b[0m X_test_vec \u001b[38;5;241m=\u001b[39m final_vec\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m---> 30\u001b[0m raw_test_pred \u001b[38;5;241m=\u001b[39m final_clf\u001b[38;5;241m.\u001b[39mpredict(X_test_vec\u001b[38;5;241m.\u001b[39mtoarray())  \u001b[38;5;66;03m# +1=inlier, -1=outlier\u001b[39;00m\n\u001b[0;32m     31\u001b[0m test_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(raw_test_pred \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 1=Real, 0=Fake\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1106\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1106\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:1327\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.23 GiB for an array with shape (8267, 20000) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- final model retrain ---\n",
    "final_vec = TfidfVectorizer(\n",
    "    max_features=best_params['tfidf__max_features'],\n",
    "    ngram_range=best_params['tfidf__ngram_range'],\n",
    "    stop_words='english'\n",
    ")\n",
    "X_real_combined = pd.concat([X_train_real_raw, X_val_raw[y_val == 1]])  # only real from train+val\n",
    "X_combined_vec = final_vec.fit_transform(X_real_combined)\n",
    "\n",
    "final_clf = LocalOutlierFactor(\n",
    "    n_neighbors=best_params['lof__n_neighbors'],\n",
    "    contamination=best_params['lof__contamination'],\n",
    "    novelty=True\n",
    ")\n",
    "final_clf.fit(X_combined_vec.toarray())\n",
    "\n",
    "# PREDICT on test\n",
    "X_test_vec = final_vec.transform(X_test_raw)\n",
    "raw_test = final_clf.predict(X_test_vec.toarray())\n",
    "test_preds = np.where(raw_test == 1, 1, 0)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\n",
    "print(classification_report(y_test, test_preds, target_names=['Fake','Real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790cc0ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
